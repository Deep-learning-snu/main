{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "58820b8a-561e-4fb0-a43a-0752f592e307",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accuracy=full_model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "46507d03-cebb-49eb-b6ef-20961658f28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9564032554626465\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf814349-3345-4e0f-a76b-fcc67002f6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 28s 605ms/step - loss: 0.3049 - sparse_categorical_accuracy: 0.9264\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy=model1.evaluate(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "727a77b3-d204-414f-a0d5-44c6666c14dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9264305233955383\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Accuracy\",accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f970f680-1712-40a5-843d-21ac0c8a2f63",
   "metadata": {},
   "source": [
    "---\n",
    "## model1 summary, flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d0248597-0913-4b41-b0eb-27ad29f18022",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9JKQ00sbXr9x"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2_as_graph\n",
    "\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a5832238-fa46-41f2-8556-fc0448ddfdaa",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OslDuZMWt2p2"
   },
   "outputs": [],
   "source": [
    "def get_flops(model, batch_size=None):\n",
    "    if batch_size is None:\n",
    "        batch_size = 1\n",
    "\n",
    "    real_model = tf.function(model).get_concrete_function(tf.TensorSpec([batch_size] + model.inputs[0].shape[1:], model.inputs[0].dtype))\n",
    "    frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(real_model)\n",
    "\n",
    "    run_meta = tf.compat.v1.RunMetadata()\n",
    "    opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "    flops = tf.compat.v1.profiler.profile(graph=frozen_func.graph,\n",
    "                                            run_meta=run_meta, cmd='op', options=opts)\n",
    "    return flops.total_float_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d50af714-774a-4042-bc31-46f4d2f58eb3",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Gqxn3M3XIjD"
   },
   "outputs": [],
   "source": [
    "def main(batch_size):\n",
    "    model1.summary()\n",
    "\n",
    "    flops = get_flops(model1, batch_size)\n",
    "    print(f\"FLOPS: {flops}\")\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "887b9d07-5ada-4878-8751-3ac56d136481",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "colab_type": "code",
    "id": "LgoSig0wchZ0",
    "outputId": "fd61e06c-466b-4df7-c0da-733e893a418f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " moat (MOAT)                 {'stage1': (None, 128, 1  4809320   \n",
      "                             28, 40),                            \n",
      "                              'res1': (None, 128, 128            \n",
      "                             , 40),                              \n",
      "                              'stage2': (None, 64, 64            \n",
      "                             , 40),                              \n",
      "                              'res2': (None, 64, 64,             \n",
      "                             40),                                \n",
      "                              'stage3': (None, 32, 32            \n",
      "                             , 80),                              \n",
      "                              'res3': (None, 32, 32,             \n",
      "                             80),                                \n",
      "                              'stage4': (None, 16, 16            \n",
      "                             , 160),                             \n",
      "                              'res4': (None, 16, 16,             \n",
      "                             160),                               \n",
      "                              'stage5': (None, 8, 8,             \n",
      "                             320),                               \n",
      "                              'res5': (None, 8, 8, 32            \n",
      "                             0)}                                 \n",
      "                                                                 \n",
      " flatten_layer1 (Flatten)    (None, 20480)             0         \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 5)                 102405    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,911,725\n",
      "Trainable params: 4,874,765\n",
      "Non-trainable params: 36,960\n",
      "_________________________________________________________________\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "op: The nodes are operation kernel type, such as MatMul, Conv2D. Graph nodes belonging to the same type are aggregated together.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "Conv2D                   36.95b float_ops (100.00%, 94.41%)\n",
      "DepthwiseConv2dNative    1.04b float_ops (5.59%, 2.65%)\n",
      "Mul                      636.72m float_ops (2.94%, 1.63%)\n",
      "Softmax                  190.05m float_ops (1.31%, 0.49%)\n",
      "RealDiv                  184.81m float_ops (0.82%, 0.47%)\n",
      "Mean                     47.19m float_ops (0.35%, 0.12%)\n",
      "BiasAdd                  37.71m float_ops (0.23%, 0.10%)\n",
      "AvgPool                  33.91m float_ops (0.14%, 0.09%)\n",
      "SquaredDifference        10.49m float_ops (0.05%, 0.03%)\n",
      "Sub                      5.26m float_ops (0.02%, 0.01%)\n",
      "MatMul                   3.28m float_ops (0.01%, 0.01%)\n",
      "Rsqrt                    98.40k float_ops (0.00%, 0.00%)\n",
      "\n",
      "======================End of Report==========================\n",
      "FLOPS: 39140858320\n"
     ]
    }
   ],
   "source": [
    "m = main(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44471746-29d4-415a-8a07-9f68cf9f6b31",
   "metadata": {},
   "source": [
    "---\n",
    "### full_model summary, flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a2f52d08-62a2-4ac0-aecf-9ea960620dbe",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Gqxn3M3XIjD"
   },
   "outputs": [],
   "source": [
    "def main(batch_size):\n",
    "    full_model.summary()\n",
    "\n",
    "    flops = get_flops(full_model, batch_size)\n",
    "    print(f\"FLOPS: {flops}\")\n",
    "    return full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8f471dc2-164b-4e76-aef5-5dc697488c4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "colab_type": "code",
    "id": "LgoSig0wchZ0",
    "outputId": "fd61e06c-466b-4df7-c0da-733e893a418f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_16 (InputLayer)          [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " moat3 (MOAT)                   {'stage1': (None, 1  4809320     ['input_16[0][0]']               \n",
      "                                28, 128, 40),                                                     \n",
      "                                 'res1': (None, 128                                               \n",
      "                                , 128, 40),                                                       \n",
      "                                 'stage2': (None, 6                                               \n",
      "                                4, 64, 40),                                                       \n",
      "                                 'res2': (None, 64,                                               \n",
      "                                 64, 40),                                                         \n",
      "                                 'stage3': (None, 3                                               \n",
      "                                2, 32, 80),                                                       \n",
      "                                 'res3': (None, 32,                                               \n",
      "                                 32, 80),                                                         \n",
      "                                 'stage4': (None, 1                                               \n",
      "                                6, 16, 160),                                                      \n",
      "                                 'res4': (None, 16,                                               \n",
      "                                 16, 160),                                                        \n",
      "                                 'stage5': (None, 8                                               \n",
      "                                , 8, 320),                                                        \n",
      "                                 'res5': (None, 8,                                                \n",
      "                                8, 320)}                                                          \n",
      "                                                                                                  \n",
      " moat4 (MOAT)                   {'stage1': (None, 1  4809320     ['input_16[0][0]']               \n",
      "                                28, 128, 40),                                                     \n",
      "                                 'res1': (None, 128                                               \n",
      "                                , 128, 40),                                                       \n",
      "                                 'stage2': (None, 6                                               \n",
      "                                4, 64, 40),                                                       \n",
      "                                 'res2': (None, 64,                                               \n",
      "                                 64, 40),                                                         \n",
      "                                 'stage3': (None, 3                                               \n",
      "                                2, 32, 80),                                                       \n",
      "                                 'res3': (None, 32,                                               \n",
      "                                 32, 80),                                                         \n",
      "                                 'stage4': (None, 1                                               \n",
      "                                6, 16, 160),                                                      \n",
      "                                 'res4': (None, 16,                                               \n",
      "                                 16, 160),                                                        \n",
      "                                 'stage5': (None, 8                                               \n",
      "                                , 8, 320),                                                        \n",
      "                                 'res5': (None, 8,                                                \n",
      "                                8, 320)}                                                          \n",
      "                                                                                                  \n",
      " flatten_layer1 (Flatten)       (None, 20480)        0           ['moat3[1][9]']                  \n",
      "                                                                                                  \n",
      " flatten_layer2 (Flatten)       (None, 20480)        0           ['moat4[1][9]']                  \n",
      "                                                                                                  \n",
      " tf.concat_2 (TFOpLambda)       (None, 40960)        0           ['flatten_layer1[0][0]',         \n",
      "                                                                  'flatten_layer2[0][0]']         \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 256)          10486016    ['tf.concat_2[0][0]']            \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 5)            1285        ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 20,105,941\n",
      "Trainable params: 10,487,301\n",
      "Non-trainable params: 9,618,640\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "op: The nodes are operation kernel type, such as MatMul, Conv2D. Graph nodes belonging to the same type are aggregated together.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "Conv2D                   73.91b float_ops (100.00%, 94.02%)\n",
      "DepthwiseConv2dNative    2.08b float_ops (5.98%, 2.64%)\n",
      "Mul                      1.27b float_ops (3.34%, 1.62%)\n",
      "Softmax                  380.11m float_ops (1.72%, 0.48%)\n",
      "RealDiv                  369.63m float_ops (1.24%, 0.47%)\n",
      "MatMul                   335.59m float_ops (0.77%, 0.43%)\n",
      "Mean                     94.37m float_ops (0.34%, 0.12%)\n",
      "BiasAdd                  75.41m float_ops (0.22%, 0.10%)\n",
      "AvgPool                  67.83m float_ops (0.13%, 0.09%)\n",
      "SquaredDifference        20.97m float_ops (0.04%, 0.03%)\n",
      "Sub                      10.52m float_ops (0.01%, 0.01%)\n",
      "Rsqrt                    196.80k float_ops (0.00%, 0.00%)\n",
      "\n",
      "======================End of Report==========================\n",
      "FLOPS: 78610764224\n"
     ]
    }
   ],
   "source": [
    "m = main(16)\n",
    "# FLOPS = 32 * 32 * 3 (= 3072) * 10 * 2 + 10 = 61450"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
