{"cells":[{"cell_type":"markdown","id":"e17afc88","metadata":{"id":"e17afc88"},"source":["### colab으로 할 때만 실행"]},{"cell_type":"code","execution_count":1,"id":"50ce367d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"50ce367d","executionInfo":{"status":"ok","timestamp":1671087150640,"user_tz":-540,"elapsed":2480,"user":{"displayName":"­정다연 / 학생 / 통계학과","userId":"06805092502741452281"}},"outputId":"cd28848f-9989-4902-b20f-6cd594896921"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":2,"id":"46a28b52","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"46a28b52","executionInfo":{"status":"ok","timestamp":1671087162707,"user_tz":-540,"elapsed":1285,"user":{"displayName":"­정다연 / 학생 / 통계학과","userId":"06805092502741452281"}},"outputId":"fd054249-bb0c-4010-e827-f47b6db0e83d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Dec 15 06:52:41 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   75C    P0    34W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":3,"id":"83dbb8ac","metadata":{"id":"83dbb8ac","executionInfo":{"status":"ok","timestamp":1671087164014,"user_tz":-540,"elapsed":4,"user":{"displayName":"­정다연 / 학생 / 통계학과","userId":"06805092502741452281"}}},"outputs":[],"source":["import os\n","os.chdir(\"/content/drive/MyDrive\")"]},{"cell_type":"markdown","id":"98aeea95","metadata":{"id":"98aeea95"},"source":["### 설치 필요할때만"]},{"cell_type":"code","execution_count":null,"id":"f2608bff","metadata":{"id":"f2608bff"},"outputs":[],"source":["!python --version\n","!pip install opencv-python\n","!pip install tensorflow_datasets\n","!pip install -U scikit-learn\n","!pip install adabelief-tf\n","!pip install scipy"]},{"cell_type":"markdown","id":"a9d6dc14","metadata":{"id":"a9d6dc14"},"source":["### 기본 설정"]},{"cell_type":"code","execution_count":4,"id":"90beabc7","metadata":{"executionInfo":{"elapsed":4866,"status":"ok","timestamp":1671087172226,"user":{"displayName":"­정다연 / 학생 / 통계학과","userId":"06805092502741452281"},"user_tz":-540},"id":"90beabc7"},"outputs":[],"source":["from shutil import copy\n","from collections import defaultdict\n","import scipy\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import random\n","import cv2\n","import glob\n","from PIL import Image, ImageEnhance\n","import PIL.ImageOps\n","\n","import torch\n","import torchvision\n","from torch import nn\n","\n","import warnings\n","\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","\n","# 0 = all messages are logged (default behavior)\n","# 1 = INFO messages are not printed\n","# 2 = INFO and WARNING messages are not printed\n","# 3 = INFO, WARNING, and ERROR messages are not printed\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.python.ops.clip_ops import clip_by_global_norm\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras import layers\n","import tensorflow_datasets as tfds\n","\n","\n","# Theano(th)와 Tensorflow(tf) 모두와 호환이 되는 Keras 모듈을 작성\n","import keras.backend as K\n","from keras import regularizers\n","from keras.applications.mobilenet_v2 import MobileNetV2\n","from keras.models import Model, Sequential\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization, Dropout, Flatten, Dense, concatenate\n","from tensorflow.keras.utils import to_categorical\n","from keras.preprocessing.image import ImageDataGenerator # 데이터 전처리\n","from keras.callbacks import ModelCheckpoint, CSVLogger\n","#from keras.optimizers import SGD\n","\n","from keras_preprocessing.image import array_to_img, img_to_array, load_img\n","\n","from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n","\n","\n","from deeplab2.model.pixel_encoder import moat\n","from adabelief_tf import AdaBeliefOptimizer"]},{"cell_type":"markdown","id":"03cddefb","metadata":{"id":"03cddefb"},"source":["### 데이터 불러오기"]},{"cell_type":"markdown","id":"92f5ad74","metadata":{"id":"92f5ad74"},"source":["### https://www.tensorflow.org/datasets/catalog/cifar100"]},{"cell_type":"code","execution_count":5,"id":"0d405946","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1122,"status":"ok","timestamp":1671087179360,"user":{"displayName":"­정다연 / 학생 / 통계학과","userId":"06805092502741452281"},"user_tz":-540},"id":"0d405946","outputId":"faad1776-122f-454c-ccdd-e356338ecc63","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Train: (50000, 32, 32, 3) (50000, 1)\n","Train1: (25000, 32, 32, 3) (25000, 1)\n","Train2: (25000, 32, 32, 3) (25000, 1)\n","Test: (10000, 32, 32, 3) (10000, 1)\n"]}],"source":["# 'cifar100' 대신 'food101' 이나 다른 데이터셋 이름 넣으면 ok\n","from tensorflow.keras.datasets import cifar100\n","\n","(train_images, train_labels), (test_images, test_labels) = cifar100.load_data()\n","\n","tr1_images, tr2_images, tr1_labels, tr2_labels = train_test_split(train_images, train_labels, test_size=0.5, shuffle=False)\n","\n","nb_train_samples =  train_images.shape[0]\n","nb_train1_samples =  tr1_images.shape[0]\n","nb_train2_samples =  tr2_images.shape[0] \n","nb_test_samples = test_images.shape[0]\n","batch_size = 32\n","\n","print('Train:', train_images.shape, train_labels.shape)\n","print('Train1:', tr1_images.shape, tr1_labels.shape)\n","print('Train2:', tr2_images.shape, tr2_labels.shape)\n","print('Test:', test_images.shape, test_labels.shape)\n","\n","#print(np.unique(tr_labels, return_counts = True))\n","#print(np.unique(tr1_labels, return_counts = True))\n","#print(np.unique(tr2_labels, return_counts = True))\n","#print(np.unique(test_labels, return_counts = True))"]},{"cell_type":"markdown","id":"a45fb2f6","metadata":{"id":"a45fb2f6"},"source":["### ImageDataGenerator"]},{"cell_type":"code","execution_count":6,"id":"584633bf","metadata":{"id":"584633bf","executionInfo":{"status":"ok","timestamp":1671087183075,"user_tz":-540,"elapsed":453,"user":{"displayName":"­정다연 / 학생 / 통계학과","userId":"06805092502741452281"}}},"outputs":[],"source":["train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.3,\n","    height_shift_range=0.3,\n","    shear_range=0.3,        # Shear angle in counter-clockwise direction as radians\n","    zoom_range=0.3,         # Range for random zoom. If a float\n","    horizontal_flip=True,   # Randomly flip inputs horizontally\n","    fill_mode='nearest') \n","\n","test_datagen = ImageDataGenerator(\n","    rescale=1./255,)"]},{"cell_type":"markdown","id":"b420228f","metadata":{"id":"b420228f"},"source":["### 모델 생성"]},{"cell_type":"code","execution_count":7,"id":"01d3d299","metadata":{"id":"01d3d299","executionInfo":{"status":"ok","timestamp":1671087192574,"user_tz":-540,"elapsed":7498,"user":{"displayName":"­정다연 / 학생 / 통계학과","userId":"06805092502741452281"}}},"outputs":[],"source":["moat1 = moat.get_model(name='tiny_moat1_pretrain_256_no_pe_1k',input_shape=[32,32,3])\n","moat1 = moat._load_moat_pretrained_checkpoint(moat1, path=\"./model-ckpt-0\")\n","\n","o1 = moat1.output[\"stage5\"]\n","r1 = tf.keras.layers.Flatten(name='flatten_layer1')(o1)\n","r1 = tf.keras.layers.BatchNormalization()(r1)\n","out1 = tf.keras.layers.Dense(\n","    units=100, activation='softmax', name='output_layer', kernel_initializer=\"he_normal\")(r1)  \n","\n","def create_model1():\n","    return tf.keras.models.Model(moat1.input, out1)"]},{"cell_type":"code","execution_count":8,"id":"4af7b671","metadata":{"id":"4af7b671","executionInfo":{"status":"ok","timestamp":1671087195047,"user_tz":-540,"elapsed":2480,"user":{"displayName":"­정다연 / 학생 / 통계학과","userId":"06805092502741452281"}}},"outputs":[],"source":["moat2 = moat.get_model(name='tiny_moat1_pretrain_256_no_pe_1k',input_shape=[32,32,3])\n","moat2 = moat._load_moat_pretrained_checkpoint(moat2, path=\"./model-ckpt-0\")\n","\n","o2 = moat2.output[\"stage5\"]\n","r2 = tf.keras.layers.Flatten(name='flatten_layer1')(o2)\n","r2 = tf.keras.layers.BatchNormalization()(r2)\n","out2 = tf.keras.layers.Dense(\n","    units=100, activation='softmax', name='output_layer', kernel_initializer=\"he_normal\")(r2)  \n","\n","def create_model2():\n","    return tf.keras.models.Model(moat2.input, out2)"]},{"cell_type":"code","execution_count":null,"id":"8188e5a9","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"8188e5a9","outputId":"fbe66618-ac52-4415-b3fc-00c1fcad27d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n","\u001b[31mModifications to default arguments:\n","\u001b[31m                           eps  weight_decouple    rectify\n","-----------------------  -----  -----------------  -------------\n","adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",">=0.1.0 (Current 0.2.1)  1e-14  supported          default: True\n","\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n","----------------------------------------------------------  ----------------------------------------------\n","Recommended epsilon = 1e-7                                  Recommended epsilon = 1e-14\n","\u001b[34mFor a complete table of recommended hyperparameters, see\n","\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n","\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n","\u001b[0m\n","Epoch 1/10\n","200/200 [==============================] - ETA: 0s - loss: 3.6711 - sparse_categorical_accuracy: 0.1434\n","Epoch 1: val_sparse_categorical_accuracy improved from -inf to 0.10960, saving model to cifar_final_disjoint_kfold_1_1.hdf5\n","200/200 [==============================] - 162s 222ms/step - loss: 3.6711 - sparse_categorical_accuracy: 0.1434 - val_loss: 3.6971 - val_sparse_categorical_accuracy: 0.1096\n","Epoch 2/10\n","200/200 [==============================] - ETA: 0s - loss: 2.9758 - sparse_categorical_accuracy: 0.2549\n","Epoch 2: val_sparse_categorical_accuracy improved from 0.10960 to 0.20880, saving model to cifar_final_disjoint_kfold_1_1.hdf5\n","200/200 [==============================] - 44s 218ms/step - loss: 2.9758 - sparse_categorical_accuracy: 0.2549 - val_loss: 3.4508 - val_sparse_categorical_accuracy: 0.2088\n","Epoch 3/10\n","200/200 [==============================] - ETA: 0s - loss: 2.5742 - sparse_categorical_accuracy: 0.3277\n","Epoch 3: val_sparse_categorical_accuracy improved from 0.20880 to 0.22940, saving model to cifar_final_disjoint_kfold_1_1.hdf5\n","200/200 [==============================] - 43s 214ms/step - loss: 2.5742 - sparse_categorical_accuracy: 0.3277 - val_loss: 3.3279 - val_sparse_categorical_accuracy: 0.2294\n","Epoch 4/10\n","200/200 [==============================] - ETA: 0s - loss: 2.3461 - sparse_categorical_accuracy: 0.3780\n","Epoch 4: val_sparse_categorical_accuracy improved from 0.22940 to 0.34620, saving model to cifar_final_disjoint_kfold_1_1.hdf5\n","200/200 [==============================] - 42s 212ms/step - loss: 2.3461 - sparse_categorical_accuracy: 0.3780 - val_loss: 2.5610 - val_sparse_categorical_accuracy: 0.3462\n","Epoch 5/10\n","200/200 [==============================] - ETA: 0s - loss: 2.1793 - sparse_categorical_accuracy: 0.4137\n","Epoch 5: val_sparse_categorical_accuracy improved from 0.34620 to 0.35560, saving model to cifar_final_disjoint_kfold_1_1.hdf5\n","200/200 [==============================] - 43s 212ms/step - loss: 2.1793 - sparse_categorical_accuracy: 0.4137 - val_loss: 2.6111 - val_sparse_categorical_accuracy: 0.3556\n","Epoch 6/10\n","200/200 [==============================] - ETA: 0s - loss: 2.0695 - sparse_categorical_accuracy: 0.4371\n","Epoch 6: val_sparse_categorical_accuracy did not improve from 0.35560\n","200/200 [==============================] - 41s 205ms/step - loss: 2.0695 - sparse_categorical_accuracy: 0.4371 - val_loss: 2.7406 - val_sparse_categorical_accuracy: 0.3412\n","Epoch 7/10\n","200/200 [==============================] - ETA: 0s - loss: 1.9762 - sparse_categorical_accuracy: 0.4591\n","Epoch 7: val_sparse_categorical_accuracy improved from 0.35560 to 0.38060, saving model to cifar_final_disjoint_kfold_1_1.hdf5\n","200/200 [==============================] - 42s 209ms/step - loss: 1.9762 - sparse_categorical_accuracy: 0.4591 - val_loss: 2.4953 - val_sparse_categorical_accuracy: 0.3806\n","Epoch 8/10\n","200/200 [==============================] - ETA: 0s - loss: 1.8922 - sparse_categorical_accuracy: 0.4785\n","Epoch 8: val_sparse_categorical_accuracy did not improve from 0.38060\n","200/200 [==============================] - 40s 201ms/step - loss: 1.8922 - sparse_categorical_accuracy: 0.4785 - val_loss: 3.2137 - val_sparse_categorical_accuracy: 0.3114\n","Epoch 9/10\n","200/200 [==============================] - ETA: 0s - loss: 1.8316 - sparse_categorical_accuracy: 0.4920\n","Epoch 9: val_sparse_categorical_accuracy did not improve from 0.38060\n","200/200 [==============================] - 40s 199ms/step - loss: 1.8316 - sparse_categorical_accuracy: 0.4920 - val_loss: 2.6791 - val_sparse_categorical_accuracy: 0.3604\n","Epoch 10/10\n","200/200 [==============================] - ETA: 0s - loss: 1.7558 - sparse_categorical_accuracy: 0.5066\n","Epoch 10: val_sparse_categorical_accuracy did not improve from 0.38060\n","200/200 [==============================] - 41s 207ms/step - loss: 1.7558 - sparse_categorical_accuracy: 0.5066 - val_loss: 2.8239 - val_sparse_categorical_accuracy: 0.3582\n","\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n","\u001b[31mModifications to default arguments:\n","\u001b[31m                           eps  weight_decouple    rectify\n","-----------------------  -----  -----------------  -------------\n","adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",">=0.1.0 (Current 0.2.1)  1e-14  supported          default: True\n","\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n","----------------------------------------------------------  ----------------------------------------------\n","Recommended epsilon = 1e-7                                  Recommended epsilon = 1e-14\n","\u001b[34mFor a complete table of recommended hyperparameters, see\n","\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n","\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n","\u001b[0m\n","Epoch 1/10\n","200/200 [==============================] - ETA: 0s - loss: 1.7555 - sparse_categorical_accuracy: 0.5115\n","Epoch 1: val_sparse_categorical_accuracy improved from -inf to 0.54960, saving model to cifar_final_disjoint_kfold_1_1.hdf5\n","200/200 [==============================] - 105s 221ms/step - loss: 1.7555 - sparse_categorical_accuracy: 0.5115 - val_loss: 1.6016 - val_sparse_categorical_accuracy: 0.5496\n","Epoch 2/10\n","200/200 [==============================] - ETA: 0s - loss: 1.6831 - sparse_categorical_accuracy: 0.5240\n","Epoch 2: val_sparse_categorical_accuracy did not improve from 0.54960\n","200/200 [==============================] - 40s 198ms/step - loss: 1.6831 - sparse_categorical_accuracy: 0.5240 - val_loss: 1.9457 - val_sparse_categorical_accuracy: 0.4744\n","Epoch 3/10\n","200/200 [==============================] - ETA: 0s - loss: 1.7043 - sparse_categorical_accuracy: 0.5268\n","Epoch 3: val_sparse_categorical_accuracy did not improve from 0.54960\n","200/200 [==============================] - 40s 198ms/step - loss: 1.7043 - sparse_categorical_accuracy: 0.5268 - val_loss: 2.1970 - val_sparse_categorical_accuracy: 0.4498\n","Epoch 4/10\n","200/200 [==============================] - ETA: 0s - loss: 1.6759 - sparse_categorical_accuracy: 0.5310\n","Epoch 4: val_sparse_categorical_accuracy did not improve from 0.54960\n","200/200 [==============================] - 39s 196ms/step - loss: 1.6759 - sparse_categorical_accuracy: 0.5310 - val_loss: 2.6542 - val_sparse_categorical_accuracy: 0.3704\n","Epoch 5/10\n","200/200 [==============================] - ETA: 0s - loss: 1.6436 - sparse_categorical_accuracy: 0.5381\n","Epoch 5: val_sparse_categorical_accuracy did not improve from 0.54960\n","200/200 [==============================] - 39s 196ms/step - loss: 1.6436 - sparse_categorical_accuracy: 0.5381 - val_loss: 2.8301 - val_sparse_categorical_accuracy: 0.3676\n","Epoch 6/10\n"," 83/200 [===========>..................] - ETA: 22s - loss: 1.5789 - sparse_categorical_accuracy: 0.5481"]}],"source":["warnings.filterwarnings('ignore')\n","\n","skf = StratifiedKFold(n_splits = 5)\n","\n","for train_index, test_index in skf.split(tr1_images, tr1_labels):\n","    \n","    tr_images, val_images = tr1_images[train_index], tr1_images[test_index]\n","    tr_labels, val_labels = tr1_labels[train_index], tr1_labels[test_index]\n","    \n","    nb_tr_samples =  tr_images.shape[0]\n","    nb_val_samples =  val_images.shape[0]\n","    \n","    train_generator = train_datagen.flow(x=tr_images, y=tr_labels, batch_size=100, shuffle=True)\n","    validation_generator = test_datagen.flow(x=val_images, y=val_labels, batch_size=100, shuffle=False)\n","\n","    model1 = create_model1()\n","    \n","    try:\n","        model1.load_weights('cifar_final_disjoint_kfold_1_1.hdf5')\n","    except:\n","        pass\n","        \n","\n","    opt = AdaBeliefOptimizer(learning_rate=1e-3, beta_1= 0.9, beta_2=0.999, weight_decay= 0.05,  epsilon=1e-14)\n","\n","    model1.compile(optimizer=opt,\n","              loss='sparse_categorical_crossentropy', metrics = tf.keras.metrics.SparseCategoricalAccuracy())\n","\n","    checkpointer = ModelCheckpoint(filepath='cifar_final_disjoint_kfold_1_1.hdf5', verbose=1, monitor =\"val_sparse_categorical_accuracy\",save_best_only=True)\n","    csv_logger = CSVLogger('cifar_final_disjoint_kfold_1_1.log')\n","\n","    history = model1.fit(train_generator,\n","                    steps_per_epoch = nb_tr_samples // 100,      \n","                    validation_data=validation_generator,\n","                    validation_steps=nb_val_samples // 100,  \n","                    epochs=10,                                             \n","                    verbose=1,\n","                    callbacks=[csv_logger, checkpointer])\n","\n","    "]},{"cell_type":"markdown","id":"ec404ef8","metadata":{"id":"ec404ef8"},"source":["### 데이터 불리기"]},{"cell_type":"code","execution_count":null,"id":"3da414c3","metadata":{"id":"3da414c3"},"outputs":[],"source":["train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.3,\n","    height_shift_range=0.3,\n","    shear_range=0.3,        # Shear angle in counter-clockwise direction as radians\n","    zoom_range=0.3,         # Range for random zoom. If a float\n","    horizontal_flip=True,   # Randomly flip inputs horizontally\n","    fill_mode='nearest') \n","\n","train1_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.3,\n","    height_shift_range=0.3,\n","    shear_range=0.3,        # Shear angle in counter-clockwise direction as radians\n","    zoom_range=0.3,         # Range for random zoom. If a float\n","    horizontal_flip=True,   # Randomly flip inputs horizontally\n","    fill_mode='nearest') \n","\n","train2_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.3,\n","    height_shift_range=0.3,\n","    shear_range=0.3,        # Shear angle in counter-clockwise direction as radians\n","    zoom_range=0.3,         # Range for random zoom. If a float\n","    horizontal_flip=True,   # Randomly flip inputs horizontally\n","    fill_mode='nearest') \n","\n","val_datagen = ImageDataGenerator(\n","    rescale=1./255,)\n","\n","test_datagen = ImageDataGenerator(\n","    rescale=1./255,)"]},{"cell_type":"code","execution_count":null,"id":"0acb7ff0","metadata":{"id":"0acb7ff0"},"outputs":[],"source":["# Numpy Array Iterator 객체 생성하여 모델 인풋으로 배치 사이즈만큼 집어넣을 준비\n","train_generator = train_datagen.flow(x=tr_images, y=tr_labels, batch_size=32, shuffle=True)\n","train1_generator = train1_datagen.flow(x=tr1_images, y=tr1_labels, batch_size=32, shuffle=True)\n","train2_generator = train2_datagen.flow(x=tr2_images, y=tr2_labels, batch_size=32, shuffle=True)\n","\n","validation_generator = val_datagen.flow(x=val_images, y=val_labels, batch_size=32, shuffle=False)\n","\n","test_generator = test_datagen.flow(x=test_images, y=test_labels, batch_size=32, shuffle=False)"]},{"cell_type":"markdown","id":"721e731a","metadata":{"id":"721e731a"},"source":["### 모델 생성"]},{"cell_type":"code","execution_count":null,"id":"755177fc","metadata":{"id":"755177fc"},"outputs":[],"source":["moat2 = moat.get_model(name='tiny_moat1_pretrain_256_no_pe_1k',input_shape=[32,32,3])\n","moat2 = moat._load_moat_pretrained_checkpoint(moat2, path=\"./model-ckpt-0\")\n","\n","o2 = moat2.output[\"stage5\"]\n","r2 = tf.keras.layers.Flatten(name='flatten_layer1')(o2)\n","r2 = tf.keras.layers.BatchNormalization()(r2)\n","out2 = tf.keras.layers.Dense(\n","    units=100, activation='softmax', name='output_layer', kernel_initializer=\"he_normal\")(r2)  \n","\n","def create_model():\n","    return tf.keras.models.Model(moat2.input, out2)"]},{"cell_type":"code","execution_count":null,"id":"59a4328d","metadata":{"id":"59a4328d"},"outputs":[],"source":["model2 = create_model()\n","#model2.load_weights('cifar_final_disjoint2_1.hdf5')\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","opt = AdaBeliefOptimizer(learning_rate=1e-3, beta_1= 0.9, beta_2=0.999, weight_decay= 0.05,  epsilon=1e-14)\n","\n","model2.compile(optimizer=opt,\n","          loss='sparse_categorical_crossentropy', metrics = tf.keras.metrics.SparseCategoricalAccuracy())\n","\n","checkpointer = ModelCheckpoint(filepath='cifar_final_disjoint2_1.hdf5', verbose=1, monitor =\"val_sparse_categorical_accuracy\",save_best_only=True)\n","csv_logger = CSVLogger('cifar_final_disjoint2_1.log')\n","\n","history = model2.fit(train2_generator,\n","                steps_per_epoch = nb_train2_samples // batch_size,      \n","                validation_data=validation_generator,\n","                validation_steps=nb_validation_samples // batch_size,  \n","                epochs=80,                                             \n","                verbose=1,\n","                callbacks=[csv_logger, checkpointer])"]},{"cell_type":"code","execution_count":null,"id":"3b92b8c4","metadata":{"id":"3b92b8c4"},"outputs":[],"source":["model2 = create_model()\n","model2.load_weights('cifar_final_disjoint2_1.hdf5')\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","opt = AdaBeliefOptimizer(learning_rate=1e-3, beta_1= 0.9, beta_2=0.999, weight_decay= 0.05,  epsilon=1e-14)\n","\n","model2.compile(optimizer=opt,\n","          loss='sparse_categorical_crossentropy', metrics = tf.keras.metrics.SparseCategoricalAccuracy())\n","\n","checkpointer = ModelCheckpoint(filepath='cifar_final_disjoint2_2.hdf5', verbose=1, monitor =\"val_sparse_categorical_accuracy\",save_best_only=True)\n","csv_logger = CSVLogger('cifar_final_disjoint2_2.log')\n","\n","history = model2.fit(train2_generator,\n","                steps_per_epoch = nb_train2_samples // batch_size,      \n","                validation_data=validation_generator,\n","                validation_steps=nb_validation_samples // batch_size,  \n","                epochs=80,                                             \n","                verbose=1,\n","                callbacks=[csv_logger, checkpointer])"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":5}