{"cells":[{"cell_type":"markdown","metadata":{"id":"bOsIdo62wNyH"},"source":["## 기본 세팅"],"id":"bOsIdo62wNyH"},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26987,"status":"ok","timestamp":1671086767789,"user":{"displayName":"신동욱","userId":"15777921251637057342"},"user_tz":-540},"id":"9DH5nfqOh-NV","outputId":"2f83f4df-ce35-452b-9fa1-bb27e3c8fbbd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"9DH5nfqOh-NV"},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2015,"status":"ok","timestamp":1671086774431,"user":{"displayName":"신동욱","userId":"15777921251637057342"},"user_tz":-540},"id":"3wpsE0xSw-zE","outputId":"e94abd92-61e4-4a35-e403-40e2aaeea1c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Dec 15 06:46:13 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    52W / 350W |      0MiB / 40536MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"],"id":"3wpsE0xSw-zE"},{"cell_type":"code","source":["# !unzip \"/content/drive/MyDrive/augda.zip\" -d \"/content/drive/MyDrive/augda\""],"metadata":{"id":"Egk6hA2V6eq9"},"id":"Egk6hA2V6eq9","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1671086776865,"user":{"displayName":"신동욱","userId":"15777921251637057342"},"user_tz":-540},"id":"MQ-KWx-3ij60"},"outputs":[],"source":["import os\n","os.chdir(\"/content/drive/MyDrive\")"],"id":"MQ-KWx-3ij60"},{"cell_type":"markdown","metadata":{"id":"CI0WrQFWwUZn"},"source":["## 모델 기본 세팅"],"id":"CI0WrQFWwUZn"},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24863,"status":"ok","timestamp":1671086804401,"user":{"displayName":"신동욱","userId":"15777921251637057342"},"user_tz":-540},"id":"MzgWBKQ6i_XQ","outputId":"aa1f10dd-e99a-4a4a-91b1-49b8a06180ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting adabelief_tf\n","  Downloading adabelief_tf-0.2.1-py3-none-any.whl (6.4 kB)\n","Collecting colorama>=0.4.0\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: tabulate>=0.7 in /usr/local/lib/python3.8/dist-packages (from adabelief_tf) (0.8.10)\n","Requirement already satisfied: tensorflow>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from adabelief_tf) (2.9.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->adabelief_tf) (1.14.1)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->adabelief_tf) (0.2.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->adabelief_tf) (1.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->adabelief_tf) (4.4.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->adabelief_tf) (0.28.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->adabelief_tf) (3.19.6)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->adabelief_tf) (1.15.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->adabelief_tf) (3.1.0)\n","Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->adabelief_tf) (1.12)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->adabelief_tf) (1.1.2)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->adabelief_tf) (1.6.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->adabelief_tf) (21.3)\n","Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->adabelief_tf) (2.9.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->adabelief_tf) (1.21.6)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->adabelief_tf) (1.51.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->adabelief_tf) (2.1.1)\n","Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->adabelief_tf) (2.9.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->adabelief_tf) (3.3.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->adabelief_tf) (14.0.6)\n","Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->adabelief_tf) (2.9.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->adabelief_tf) (0.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->adabelief_tf) (57.4.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0.0->adabelief_tf) (0.38.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.0.0->adabelief_tf) (2.23.0)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.0.0->adabelief_tf) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.0.0->adabelief_tf) (0.6.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.0.0->adabelief_tf) (2.15.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.0.0->adabelief_tf) (3.4.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.0.0->adabelief_tf) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.0.0->adabelief_tf) (1.8.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.0.0->adabelief_tf) (5.2.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.0.0->adabelief_tf) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.0.0->adabelief_tf) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.0.0->adabelief_tf) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.0.0->adabelief_tf) (4.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.0.0->adabelief_tf) (3.11.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.0.0->adabelief_tf) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.0.0->adabelief_tf) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.0.0->adabelief_tf) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.0.0->adabelief_tf) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.0.0->adabelief_tf) (2022.9.24)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.0.0->adabelief_tf) (3.2.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow>=2.0.0->adabelief_tf) (3.0.9)\n","Installing collected packages: colorama, adabelief-tf\n","Successfully installed adabelief-tf-0.2.1 colorama-0.4.6\n","\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n","\u001b[31mModifications to default arguments:\n","\u001b[31m                           eps  weight_decouple    rectify\n","-----------------------  -----  -----------------  -------------\n","adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",">=0.1.0 (Current 0.2.1)  1e-14  supported          default: True\n","\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n","----------------------------------------------------------  ----------------------------------------------\n","Recommended epsilon = 1e-7                                  Recommended epsilon = 1e-14\n","\u001b[34mFor a complete table of recommended hyperparameters, see\n","\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n","\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n","\u001b[0m\n","/device:GPU:0\n"]}],"source":["from deeplab2.model.pixel_encoder import moat\n","import tensorflow as tf\n","import numpy as np\n","\n","from tensorflow.python.ops.clip_ops import clip_by_global_norm\n","!pip install adabelief_tf\n","from tensorflow.keras.layers import (Input, Dense, concatenate, Conv2D, MaxPooling2D, Flatten)\n","from tensorflow import keras\n","from adabelief_tf import AdaBeliefOptimizer\n","opt = AdaBeliefOptimizer(learning_rate=1e-3, beta_1= 0.9, beta_2=0.999, weight_decay= 0.01, epsilon=1e-7)\n","\n","from shutil import copy\n","from collections import defaultdict\n","import scipy\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import random\n","import cv2\n","import glob\n","from PIL import Image, ImageEnhance\n","import PIL.ImageOps\n","\n","import torch\n","import torchvision\n","from torch import nn\n","\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","\n","# 0 = all messages are logged (default behavior)\n","# 1 = INFO messages are not printed\n","# 2 = INFO and WARNING messages are not printed\n","# 3 = INFO, WARNING, and ERROR messages are not printed\n","\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras import layers\n","import tensorflow_datasets as tfds\n","\n","# Theano(th)와 Tensorflow(tf) 모두와 호환이 되는 Keras 모듈을 작성\n","import keras.backend as K\n","from keras import regularizers\n","from keras.applications.mobilenet_v2 import MobileNetV2\n","from keras.models import Model\n","from keras.layers import Dense, Dropout, Conv2D\n","from keras.layers import GlobalAveragePooling2D\n","from keras.preprocessing.image import ImageDataGenerator # 데이터 전처리\n","from keras.callbacks import ModelCheckpoint, CSVLogger\n","#from keras.optimizers import SGD\n","\n","from keras_preprocessing.image import array_to_img, img_to_array, load_img\n","\n","print(tf.test.gpu_device_name())\n","\n","K.clear_session()"],"id":"MzgWBKQ6i_XQ"},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1671086804401,"user":{"displayName":"신동욱","userId":"15777921251637057342"},"user_tz":-540},"id":"_jYIZU4nUYJ0"},"outputs":[],"source":["# 초기 변수 설정\n","n_classes = 37\n","\n","### 이미지 크기 설정\n","img_width, img_height = 500, 500\n","\n","train_data_dir = '/content/drive/MyDrive/augda/train'\n","train1_data_dir = '/content/drive/MyDrive/augda/train1'\n","train2_data_dir = '/content/drive/MyDrive/augda/train2'\n","validation_data_dir = '/content/drive/MyDrive/augda/validation'\n","validation_data2_dir = '/content/drive/MyDrive/augda/validation'\n","test_data_dir = '/content/drive/MyDrive/augda/test'\n","\n","nb_train_samples =  2576*4\n","nb_train1_samples =  1282*4\n","nb_train2_samples =  1282*4\n","nb_validation_samples = 1104\n","nb_validation2_samples = 1104\n","nb_test_samples = 3668\n","batch_size = 16"],"id":"_jYIZU4nUYJ0"},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1671086806401,"user":{"displayName":"신동욱","userId":"15777921251637057342"},"user_tz":-540},"id":"RcX6LADtUYPv"},"outputs":[],"source":["# ImageDataGenerator 객체 생성 (이미지 파일들을 Numpy Array 형태로 가져온 후 증강 기법 적용 준비)\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.3,\n","    height_shift_range=0.3,\n","    shear_range=0.3,        # Shear angle in counter-clockwise direction as radians\n","    zoom_range=0.3,         # Range for random zoom. If a float\n","    horizontal_flip=True,   # Randomly flip inputs horizontally\n","    fill_mode='nearest') \n","\n","train3_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.3,\n","    height_shift_range=0.3,\n","    shear_range=0.3,        # Shear angle in counter-clockwise direction as radians\n","    zoom_range=0.3,         # Range for random zoom. If a float\n","    horizontal_flip=True,   # Randomly flip inputs horizontally\n","    fill_mode='nearest')\n","\n","train1_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.3,\n","    height_shift_range=0.3,\n","    shear_range=0.3,        # Shear angle in counter-clockwise direction as radians\n","    zoom_range=0.3,         # Range for random zoom. If a float\n","    horizontal_flip=True,   # Randomly flip inputs horizontally\n","    fill_mode='nearest')   \n","\n","# ImageDataGenerator 객체 생성 (이미지 파일들을 Numpy Array 형태로 가져온 후 증강 기법 적용 준비)\n","train2_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.3,\n","    height_shift_range=0.3,\n","    shear_range=0.3,        # Shear angle in counter-clockwise direction as radians\n","    zoom_range=0.3,         # Range for random zoom. If a float\n","    horizontal_flip=True,   # Randomly flip inputs horizontally\n","    fill_mode='nearest') \n","\n","val_datagen = ImageDataGenerator(\n","    rescale=1./255,)\n","val_datagen2 = ImageDataGenerator(\n","    rescale=1./255,)\n","test_datagen = ImageDataGenerator(\n","    rescale=1./255,)\n"],"id":"RcX6LADtUYPv"},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27424,"status":"ok","timestamp":1671086835231,"user":{"displayName":"신동욱","userId":"15777921251637057342"},"user_tz":-540},"id":"Nafyq4AgUYUk","outputId":"86b6cc92-ecdf-4d42-9cfe-d48482f60e91"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 10304 images belonging to 37 classes.\n","Found 10304 images belonging to 37 classes.\n","Found 5128 images belonging to 37 classes.\n","Found 5128 images belonging to 37 classes.\n","Found 1104 images belonging to 37 classes.\n","Found 1104 images belonging to 37 classes.\n","Found 3668 images belonging to 37 classes.\n"]}],"source":["# flow_from_directory : Numpy Array Iterator 객체 생성\n","# 인자로 설정해주는 directory의 바로 하위 디렉토리 이름을 레이블이라고 간주, 그 디렉토리 아래의 파일들을 해당 레이블의 이미지들이라고 알아서 추측\n","\n","import tensorflow as tf\n","import numpy as np\n","import cv2\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='sparse')\n","\n","train3_generator = train3_datagen.flow_from_directory(\n","    train_data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='sparse')\n","\n","train1_generator = train1_datagen.flow_from_directory(\n","    train1_data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='sparse')\n","\n","\n","train2_generator = train2_datagen.flow_from_directory(\n","    train2_data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='sparse')\n","    \n","  \n","validation2_generator = val_datagen.flow_from_directory(\n","    validation_data2_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='sparse')\n","\n","validation_generator = val_datagen.flow_from_directory(\n","    validation_data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='sparse')\n","\n","\n","test_generator = test_datagen.flow_from_directory(\n","    test_data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    shuffle=False,\n","    class_mode=None)\n"],"id":"Nafyq4AgUYUk"},{"cell_type":"markdown","metadata":{"id":"6LGK-Kx8YWYp"},"source":["## Train set 1"],"id":"6LGK-Kx8YWYp"},{"cell_type":"code","execution_count":null,"metadata":{"id":"XtW8Fo9-IDyt","colab":{"base_uri":"https://localhost:8080/","height":437},"outputId":"53424f8c-992b-4346-e5ff-b4bdf654e100","executionInfo":{"status":"error","timestamp":1671085648059,"user_tz":-540,"elapsed":8153,"user":{"displayName":"­신동욱 / 학생 / 통계학과","userId":"15822326990747252140"}}},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-811e6c560954>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmoat1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmoat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tiny_moat1_pretrain_256_no_pe_1k'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmoat1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmoat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_moat_pretrained_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoat1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./model-ckpt-0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mo1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmoat1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage5\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'flatten_layer1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/deeplab2/model/pixel_encoder/moat.py\u001b[0m in \u001b[0;36m_load_moat_pretrained_checkpoint\u001b[0;34m(moat, path, strict_loading)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0mvar_mean_before_loading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m     \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_to_find\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m     \u001b[0mvar_mean_after_loading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     if tf.math.equal(var_mean_before_loading,\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36mget_tensor\u001b[0;34m(self, tensor_str)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;34m\"\"\"Get the tensor from the Checkpoint object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     return CheckpointReader.CheckpointReader_GetTensor(\n\u001b[0m\u001b[1;32m     67\u001b[0m         self, compat.as_bytes(tensor_str))\n\u001b[1;32m     68\u001b[0m   \u001b[0;31m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["moat1 = moat.get_model(name='tiny_moat1_pretrain_256_no_pe_1k',input_shape=[500,500,3])\n","moat1 = moat._load_moat_pretrained_checkpoint(moat1, path=\"./model-ckpt-0\")\n","o1 = moat1.output[\"stage5\"]\n","\n","r1 = tf.keras.layers.Flatten(name='flatten_layer1')(o1)\n","r1= tf.keras.layers.BatchNormalization()(r1)\n","out1 = tf.keras.layers.Dense(\n","    units=37, activation='softmax', name='output_layer', kernel_initializer=\"he_normal\")(r1)  \n","\n","def create_model():\n","  return tf.keras.models.Model(moat1.input, out1)\n","\n","with tf.device('/device:GPU:0'):\n","  model1=create_model()\n","  # moat1 = moat._load_moat_pretrained_checkpoint(moat1, path=\"./model-ckpt-0\")\n","  opt2 = AdaBeliefOptimizer(learning_rate=1e-5, beta_1= 0.9, beta_2=0.999, weight_decay= 0.05,  epsilon=1e-14)\n","  # opt2 = AdaBeliefOptimizer(learning_rate=1e-3, beta_1= 0.9, beta_2=0.999, weight_decay= 0.01, epsilon=1e-7)\n","  model1.compile(optimizer=opt2,\n","              loss='sparse_categorical_crossentropy', metrics = tf.keras.metrics.SparseCategoricalAccuracy())\n","  checkpointer = ModelCheckpoint(filepath='pet_500_disjoint1_augment.hdf5', verbose=1, monitor =\"val_sparse_categorical_accuracy\",save_best_only=True)\n","  csv_logger = CSVLogger('pet_500_disjoint1_augment.log')\n","  history = model1.fit_generator(train1_generator,\n","                    steps_per_epoch = nb_train1_samples // batch_size,      \n","                    validation_data=validation_generator,\n","                    validation_steps=nb_validation_samples // batch_size,  \n","                    epochs=40,                                             \n","                    verbose=1,\n","                    callbacks=[csv_logger, checkpointer])\n","  \n","\n","#########################################################\n","moat1.save_weights('moat_pet_500_disjoint1_augment.h5')"],"id":"XtW8Fo9-IDyt"},{"cell_type":"code","source":["moat1.save_weights('moat_pet_500_disjoint1_augment.h5')"],"metadata":{"id":"_pp8n8MqiUEL"},"id":"_pp8n8MqiUEL","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Train set 2"],"metadata":{"id":"saHz9sASEnfm"},"id":"saHz9sASEnfm"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0gg531yS3jl3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671031011692,"user_tz":-540,"elapsed":11224050,"user":{"displayName":"신동욱","userId":"15777921251637057342"}},"outputId":"f6a66fac-d5b5-45e9-87ea-fe112dcf404f"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n","\u001b[31mModifications to default arguments:\n","\u001b[31m                           eps  weight_decouple    rectify\n","-----------------------  -----  -----------------  -------------\n","adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",">=0.1.0 (Current 0.2.1)  1e-14  supported          default: True\n","\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n","----------------------------------------------------------  ----------------------------------------------\n","Recommended epsilon = 1e-7                                  Recommended epsilon = 1e-14\n","\u001b[34mFor a complete table of recommended hyperparameters, see\n","\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n","\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n","\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-20-9b90509d35c9>:20: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  history = model2.fit_generator(train2_generator,\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/40\n","160/160 [==============================] - ETA: 0s - loss: 3.9908 - sparse_categorical_accuracy: 0.0697\n","Epoch 1: val_sparse_categorical_accuracy improved from -inf to 0.02849, saving model to pet_500_disjoint2_augment.hdf5\n","160/160 [==============================] - 342s 2s/step - loss: 3.9908 - sparse_categorical_accuracy: 0.0697 - val_loss: 5.8910 - val_sparse_categorical_accuracy: 0.0285\n","Epoch 2/40\n","160/160 [==============================] - ETA: 0s - loss: 2.4629 - sparse_categorical_accuracy: 0.3277\n","Epoch 2: val_sparse_categorical_accuracy did not improve from 0.02849\n","160/160 [==============================] - 279s 2s/step - loss: 2.4629 - sparse_categorical_accuracy: 0.3277 - val_loss: 5.4635 - val_sparse_categorical_accuracy: 0.0285\n","Epoch 3/40\n","160/160 [==============================] - ETA: 0s - loss: 1.3603 - sparse_categorical_accuracy: 0.5979\n","Epoch 3: val_sparse_categorical_accuracy improved from 0.02849 to 0.08088, saving model to pet_500_disjoint2_augment.hdf5\n","160/160 [==============================] - 280s 2s/step - loss: 1.3603 - sparse_categorical_accuracy: 0.5979 - val_loss: 4.5687 - val_sparse_categorical_accuracy: 0.0809\n","Epoch 4/40\n","160/160 [==============================] - ETA: 0s - loss: 0.8742 - sparse_categorical_accuracy: 0.7300\n","Epoch 4: val_sparse_categorical_accuracy improved from 0.08088 to 0.74908, saving model to pet_500_disjoint2_augment.hdf5\n","160/160 [==============================] - 280s 2s/step - loss: 0.8742 - sparse_categorical_accuracy: 0.7300 - val_loss: 0.7672 - val_sparse_categorical_accuracy: 0.7491\n","Epoch 5/40\n","160/160 [==============================] - ETA: 0s - loss: 0.6507 - sparse_categorical_accuracy: 0.7889\n","Epoch 5: val_sparse_categorical_accuracy improved from 0.74908 to 0.85386, saving model to pet_500_disjoint2_augment.hdf5\n","160/160 [==============================] - 279s 2s/step - loss: 0.6507 - sparse_categorical_accuracy: 0.7889 - val_loss: 0.4212 - val_sparse_categorical_accuracy: 0.8539\n","Epoch 6/40\n","160/160 [==============================] - ETA: 0s - loss: 0.5059 - sparse_categorical_accuracy: 0.8310\n","Epoch 6: val_sparse_categorical_accuracy improved from 0.85386 to 0.87224, saving model to pet_500_disjoint2_augment.hdf5\n","160/160 [==============================] - 280s 2s/step - loss: 0.5059 - sparse_categorical_accuracy: 0.8310 - val_loss: 0.3762 - val_sparse_categorical_accuracy: 0.8722\n","Epoch 7/40\n","160/160 [==============================] - ETA: 0s - loss: 0.4182 - sparse_categorical_accuracy: 0.8595\n","Epoch 7: val_sparse_categorical_accuracy did not improve from 0.87224\n","160/160 [==============================] - 279s 2s/step - loss: 0.4182 - sparse_categorical_accuracy: 0.8595 - val_loss: 0.3695 - val_sparse_categorical_accuracy: 0.8695\n","Epoch 8/40\n","160/160 [==============================] - ETA: 0s - loss: 0.3766 - sparse_categorical_accuracy: 0.8713\n","Epoch 8: val_sparse_categorical_accuracy improved from 0.87224 to 0.88879, saving model to pet_500_disjoint2_augment.hdf5\n","160/160 [==============================] - 281s 2s/step - loss: 0.3766 - sparse_categorical_accuracy: 0.8713 - val_loss: 0.3393 - val_sparse_categorical_accuracy: 0.8888\n","Epoch 9/40\n","160/160 [==============================] - ETA: 0s - loss: 0.3059 - sparse_categorical_accuracy: 0.8982\n","Epoch 9: val_sparse_categorical_accuracy improved from 0.88879 to 0.89522, saving model to pet_500_disjoint2_augment.hdf5\n","160/160 [==============================] - 279s 2s/step - loss: 0.3059 - sparse_categorical_accuracy: 0.8982 - val_loss: 0.3160 - val_sparse_categorical_accuracy: 0.8952\n","Epoch 10/40\n","160/160 [==============================] - ETA: 0s - loss: 0.2687 - sparse_categorical_accuracy: 0.9131\n","Epoch 10: val_sparse_categorical_accuracy improved from 0.89522 to 0.90441, saving model to pet_500_disjoint2_augment.hdf5\n","160/160 [==============================] - 282s 2s/step - loss: 0.2687 - sparse_categorical_accuracy: 0.9131 - val_loss: 0.3050 - val_sparse_categorical_accuracy: 0.9044\n","Epoch 11/40\n","160/160 [==============================] - ETA: 0s - loss: 0.2371 - sparse_categorical_accuracy: 0.9144\n","Epoch 11: val_sparse_categorical_accuracy improved from 0.90441 to 0.90993, saving model to pet_500_disjoint2_augment.hdf5\n","160/160 [==============================] - 283s 2s/step - loss: 0.2371 - sparse_categorical_accuracy: 0.9144 - val_loss: 0.2834 - val_sparse_categorical_accuracy: 0.9099\n","Epoch 12/40\n","160/160 [==============================] - ETA: 0s - loss: 0.2092 - sparse_categorical_accuracy: 0.9299\n","Epoch 12: val_sparse_categorical_accuracy improved from 0.90993 to 0.91085, saving model to pet_500_disjoint2_augment.hdf5\n","160/160 [==============================] - 280s 2s/step - loss: 0.2092 - sparse_categorical_accuracy: 0.9299 - val_loss: 0.2900 - val_sparse_categorical_accuracy: 0.9108\n","Epoch 13/40\n","160/160 [==============================] - ETA: 0s - loss: 0.1930 - sparse_categorical_accuracy: 0.9325\n","Epoch 13: val_sparse_categorical_accuracy did not improve from 0.91085\n","160/160 [==============================] - 278s 2s/step - loss: 0.1930 - sparse_categorical_accuracy: 0.9325 - val_loss: 0.2860 - val_sparse_categorical_accuracy: 0.9090\n","Epoch 14/40\n","160/160 [==============================] - ETA: 0s - loss: 0.1646 - sparse_categorical_accuracy: 0.9453\n","Epoch 14: val_sparse_categorical_accuracy did not improve from 0.91085\n","160/160 [==============================] - 279s 2s/step - loss: 0.1646 - sparse_categorical_accuracy: 0.9453 - val_loss: 0.3007 - val_sparse_categorical_accuracy: 0.9062\n","Epoch 15/40\n","160/160 [==============================] - ETA: 0s - loss: 0.1519 - sparse_categorical_accuracy: 0.9492\n","Epoch 15: val_sparse_categorical_accuracy did not improve from 0.91085\n","160/160 [==============================] - 280s 2s/step - loss: 0.1519 - sparse_categorical_accuracy: 0.9492 - val_loss: 0.2969 - val_sparse_categorical_accuracy: 0.9072\n","Epoch 16/40\n","160/160 [==============================] - ETA: 0s - loss: 0.1401 - sparse_categorical_accuracy: 0.9553\n","Epoch 16: val_sparse_categorical_accuracy did not improve from 0.91085\n","160/160 [==============================] - 279s 2s/step - loss: 0.1401 - sparse_categorical_accuracy: 0.9553 - val_loss: 0.2995 - val_sparse_categorical_accuracy: 0.9053\n","Epoch 17/40\n","160/160 [==============================] - ETA: 0s - loss: 0.1273 - sparse_categorical_accuracy: 0.9590\n","Epoch 17: val_sparse_categorical_accuracy improved from 0.91085 to 0.91452, saving model to pet_500_disjoint2_augment.hdf5\n","160/160 [==============================] - 281s 2s/step - loss: 0.1273 - sparse_categorical_accuracy: 0.9590 - val_loss: 0.2999 - val_sparse_categorical_accuracy: 0.9145\n","Epoch 18/40\n","160/160 [==============================] - ETA: 0s - loss: 0.1222 - sparse_categorical_accuracy: 0.9586\n","Epoch 18: val_sparse_categorical_accuracy did not improve from 0.91452\n","160/160 [==============================] - 278s 2s/step - loss: 0.1222 - sparse_categorical_accuracy: 0.9586 - val_loss: 0.3055 - val_sparse_categorical_accuracy: 0.9090\n","Epoch 19/40\n","160/160 [==============================] - ETA: 0s - loss: 0.1137 - sparse_categorical_accuracy: 0.9672\n","Epoch 19: val_sparse_categorical_accuracy did not improve from 0.91452\n","160/160 [==============================] - 277s 2s/step - loss: 0.1137 - sparse_categorical_accuracy: 0.9672 - val_loss: 0.2864 - val_sparse_categorical_accuracy: 0.9099\n","Epoch 20/40\n","160/160 [==============================] - ETA: 0s - loss: 0.0955 - sparse_categorical_accuracy: 0.9680\n","Epoch 20: val_sparse_categorical_accuracy improved from 0.91452 to 0.91820, saving model to pet_500_disjoint2_augment.hdf5\n","160/160 [==============================] - 279s 2s/step - loss: 0.0955 - sparse_categorical_accuracy: 0.9680 - val_loss: 0.2942 - val_sparse_categorical_accuracy: 0.9182\n","Epoch 21/40\n","160/160 [==============================] - ETA: 0s - loss: 0.0898 - sparse_categorical_accuracy: 0.9706\n","Epoch 21: val_sparse_categorical_accuracy did not improve from 0.91820\n","160/160 [==============================] - 278s 2s/step - loss: 0.0898 - sparse_categorical_accuracy: 0.9706 - val_loss: 0.3114 - val_sparse_categorical_accuracy: 0.9136\n","Epoch 22/40\n","160/160 [==============================] - ETA: 0s - loss: 0.0908 - sparse_categorical_accuracy: 0.9700\n","Epoch 22: val_sparse_categorical_accuracy improved from 0.91820 to 0.91912, saving model to pet_500_disjoint2_augment.hdf5\n","160/160 [==============================] - 280s 2s/step - loss: 0.0908 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.2985 - val_sparse_categorical_accuracy: 0.9191\n","Epoch 23/40\n","160/160 [==============================] - ETA: 0s - loss: 0.0845 - sparse_categorical_accuracy: 0.9700\n","Epoch 23: val_sparse_categorical_accuracy improved from 0.91912 to 0.92096, saving model to pet_500_disjoint2_augment.hdf5\n","160/160 [==============================] - 280s 2s/step - loss: 0.0845 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.3001 - val_sparse_categorical_accuracy: 0.9210\n","Epoch 24/40\n","160/160 [==============================] - ETA: 0s - loss: 0.0789 - sparse_categorical_accuracy: 0.9731\n","Epoch 24: val_sparse_categorical_accuracy did not improve from 0.92096\n","160/160 [==============================] - 278s 2s/step - loss: 0.0789 - sparse_categorical_accuracy: 0.9731 - val_loss: 0.2914 - val_sparse_categorical_accuracy: 0.9127\n","Epoch 25/40\n","160/160 [==============================] - ETA: 0s - loss: 0.0720 - sparse_categorical_accuracy: 0.9765\n","Epoch 25: val_sparse_categorical_accuracy did not improve from 0.92096\n","160/160 [==============================] - 279s 2s/step - loss: 0.0720 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3046 - val_sparse_categorical_accuracy: 0.9191\n","Epoch 26/40\n","160/160 [==============================] - ETA: 0s - loss: 0.0612 - sparse_categorical_accuracy: 0.9824\n","Epoch 26: val_sparse_categorical_accuracy did not improve from 0.92096\n","160/160 [==============================] - 278s 2s/step - loss: 0.0612 - sparse_categorical_accuracy: 0.9824 - val_loss: 0.3054 - val_sparse_categorical_accuracy: 0.9182\n","Epoch 27/40\n","160/160 [==============================] - ETA: 0s - loss: 0.0576 - sparse_categorical_accuracy: 0.9829\n","Epoch 27: val_sparse_categorical_accuracy did not improve from 0.92096\n","160/160 [==============================] - 277s 2s/step - loss: 0.0576 - sparse_categorical_accuracy: 0.9829 - val_loss: 0.3153 - val_sparse_categorical_accuracy: 0.9191\n","Epoch 28/40\n","160/160 [==============================] - ETA: 0s - loss: 0.0574 - sparse_categorical_accuracy: 0.9814\n","Epoch 28: val_sparse_categorical_accuracy did not improve from 0.92096\n","160/160 [==============================] - 278s 2s/step - loss: 0.0574 - sparse_categorical_accuracy: 0.9814 - val_loss: 0.3039 - val_sparse_categorical_accuracy: 0.9118\n","Epoch 29/40\n","160/160 [==============================] - ETA: 0s - loss: 0.0543 - sparse_categorical_accuracy: 0.9823\n","Epoch 29: val_sparse_categorical_accuracy did not improve from 0.92096\n","160/160 [==============================] - 278s 2s/step - loss: 0.0543 - sparse_categorical_accuracy: 0.9823 - val_loss: 0.3090 - val_sparse_categorical_accuracy: 0.9108\n","Epoch 30/40\n","160/160 [==============================] - ETA: 0s - loss: 0.0533 - sparse_categorical_accuracy: 0.9835\n","Epoch 30: val_sparse_categorical_accuracy did not improve from 0.92096\n","160/160 [==============================] - 278s 2s/step - loss: 0.0533 - sparse_categorical_accuracy: 0.9835 - val_loss: 0.3281 - val_sparse_categorical_accuracy: 0.9118\n","Epoch 31/40\n","160/160 [==============================] - ETA: 0s - loss: 0.0450 - sparse_categorical_accuracy: 0.9847\n","Epoch 31: val_sparse_categorical_accuracy did not improve from 0.92096\n","160/160 [==============================] - 277s 2s/step - loss: 0.0450 - sparse_categorical_accuracy: 0.9847 - val_loss: 0.3276 - val_sparse_categorical_accuracy: 0.9136\n","Epoch 32/40\n","160/160 [==============================] - ETA: 0s - loss: 0.0452 - sparse_categorical_accuracy: 0.9851\n","Epoch 32: val_sparse_categorical_accuracy improved from 0.92096 to 0.92188, saving model to pet_500_disjoint2_augment.hdf5\n","160/160 [==============================] - 279s 2s/step - loss: 0.0452 - sparse_categorical_accuracy: 0.9851 - val_loss: 0.3317 - val_sparse_categorical_accuracy: 0.9219\n","Epoch 33/40\n","160/160 [==============================] - ETA: 0s - loss: 0.0410 - sparse_categorical_accuracy: 0.9876\n","Epoch 33: val_sparse_categorical_accuracy did not improve from 0.92188\n","160/160 [==============================] - 277s 2s/step - loss: 0.0410 - sparse_categorical_accuracy: 0.9876 - val_loss: 0.3272 - val_sparse_categorical_accuracy: 0.9154\n","Epoch 34/40\n","160/160 [==============================] - ETA: 0s - loss: 0.0480 - sparse_categorical_accuracy: 0.9849\n","Epoch 34: val_sparse_categorical_accuracy did not improve from 0.92188\n","160/160 [==============================] - 278s 2s/step - loss: 0.0480 - sparse_categorical_accuracy: 0.9849 - val_loss: 0.3140 - val_sparse_categorical_accuracy: 0.9145\n","Epoch 35/40\n","160/160 [==============================] - ETA: 0s - loss: 0.0414 - sparse_categorical_accuracy: 0.9867\n","Epoch 35: val_sparse_categorical_accuracy did not improve from 0.92188\n","160/160 [==============================] - 278s 2s/step - loss: 0.0414 - sparse_categorical_accuracy: 0.9867 - val_loss: 0.3646 - val_sparse_categorical_accuracy: 0.9072\n","Epoch 36/40\n","160/160 [==============================] - ETA: 0s - loss: 0.0343 - sparse_categorical_accuracy: 0.9888\n","Epoch 36: val_sparse_categorical_accuracy did not improve from 0.92188\n","160/160 [==============================] - 278s 2s/step - loss: 0.0343 - sparse_categorical_accuracy: 0.9888 - val_loss: 0.3485 - val_sparse_categorical_accuracy: 0.9145\n","Epoch 37/40\n","160/160 [==============================] - ETA: 0s - loss: 0.0347 - sparse_categorical_accuracy: 0.9896\n","Epoch 37: val_sparse_categorical_accuracy did not improve from 0.92188\n","160/160 [==============================] - 278s 2s/step - loss: 0.0347 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.3510 - val_sparse_categorical_accuracy: 0.9127\n","Epoch 38/40\n","160/160 [==============================] - ETA: 0s - loss: 0.0353 - sparse_categorical_accuracy: 0.9896\n","Epoch 38: val_sparse_categorical_accuracy did not improve from 0.92188\n","160/160 [==============================] - 277s 2s/step - loss: 0.0353 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.3436 - val_sparse_categorical_accuracy: 0.9154\n","Epoch 39/40\n","160/160 [==============================] - ETA: 0s - loss: 0.0387 - sparse_categorical_accuracy: 0.9872\n","Epoch 39: val_sparse_categorical_accuracy did not improve from 0.92188\n","160/160 [==============================] - 278s 2s/step - loss: 0.0387 - sparse_categorical_accuracy: 0.9872 - val_loss: 0.3289 - val_sparse_categorical_accuracy: 0.9210\n","Epoch 40/40\n","160/160 [==============================] - ETA: 0s - loss: 0.0269 - sparse_categorical_accuracy: 0.9910\n","Epoch 40: val_sparse_categorical_accuracy did not improve from 0.92188\n","160/160 [==============================] - 278s 2s/step - loss: 0.0269 - sparse_categorical_accuracy: 0.9910 - val_loss: 0.3481 - val_sparse_categorical_accuracy: 0.9191\n"]}],"source":["moat2 = moat.get_model(name='tiny_moat1_pretrain_256_no_pe_1k',input_shape=[500,500,3])\n","moat2 = moat._load_moat_pretrained_checkpoint(moat2, path=\"./model-ckpt-0\")\n","\n","o2 = moat2.output[\"stage5\"]\n","r2 = tf.keras.layers.Flatten(name='flatten_layer1')(o2)\n","r2= tf.keras.layers.BatchNormalization()(r2)\n","out2 = tf.keras.layers.Dense(\n","    units=37, activation='softmax', name='output_layer', kernel_initializer=\"he_normal\")(r2)\n","\n","def create_model2():\n","  return tf.keras.models.Model(moat2.input, out2)\n","\n","with tf.device('/device:GPU:0'):\n","  model2 = create_model2()\n","  opt2 = AdaBeliefOptimizer(learning_rate=1e-5, beta_1= 0.9, beta_2=0.999, weight_decay= 0.05,  epsilon=1e-14)\n","  model2.compile(optimizer=opt2,\n","              loss='sparse_categorical_crossentropy', metrics = tf.keras.metrics.SparseCategoricalAccuracy())\n","  checkpointer = ModelCheckpoint(filepath='pet_500_disjoint2_augment.hdf5', verbose=1, monitor =\"val_sparse_categorical_accuracy\",save_best_only=True)\n","  csv_logger = CSVLogger('pet_500_disjoint2_augment.log')\n","  history = model2.fit_generator(train2_generator,\n","                    steps_per_epoch = nb_train2_samples // batch_size,      \n","                    validation_data=validation2_generator,\n","                    validation_steps=nb_validation_samples // batch_size,  \n","                    epochs=40,                                             \n","                    verbose=1,\n","                    callbacks=[csv_logger, checkpointer])\n","  \n","#########################################################\n","moat2.save_weights('moat_pet_500_disjoint2_augment.h5')"],"id":"0gg531yS3jl3"},{"cell_type":"markdown","metadata":{"id":"i0Veqj-KK2Nl"},"source":["## Ensemble section"],"id":"i0Veqj-KK2Nl"},{"cell_type":"code","source":["first_decay_steps = 1000\n","initial_learning_rate = 1e-5\n","lr_decayed_fn = (\n","  tf.keras.experimental.CosineDecayRestarts(    \n","      initial_learning_rate,\n","      first_decay_steps))\n","\n","opt2 = AdaBeliefOptimizer(learning_rate=lr_decayed_fn, beta_1= 0.9, beta_2=0.999, weight_decay= 0.05,  epsilon=1e-14, clipnorm=1)"],"metadata":{"id":"c4cBAJl7-rjF","executionInfo":{"status":"ok","timestamp":1671085994078,"user_tz":-540,"elapsed":309,"user":{"displayName":"­신동욱 / 학생 / 통계학과","userId":"15822326990747252140"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"81425691-d9f0-4186-e3e4-ddda5ade678a"},"id":"c4cBAJl7-rjF","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n","\u001b[31mModifications to default arguments:\n","\u001b[31m                           eps  weight_decouple    rectify\n","-----------------------  -----  -----------------  -------------\n","adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",">=0.1.0 (Current 0.2.1)  1e-14  supported          default: True\n","\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n","----------------------------------------------------------  ----------------------------------------------\n","Recommended epsilon = 1e-7                                  Recommended epsilon = 1e-14\n","\u001b[34mFor a complete table of recommended hyperparameters, see\n","\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n","\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n","\u001b[0m\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gwC1ZV0_K3ss"},"outputs":[],"source":["moat3 = moat.get_model(name='tiny_moat1_pretrain_256_no_pe_1k',input_shape=[500,500,3])\n","moat4 = moat.get_model(name='tiny_moat1_pretrain_256_no_pe_1k',input_shape=[500,500,3])\n","moat3._name=\"moat3\"\n","moat4._name=\"moat4\"\n","\n","for layer in moat4.layers:\n","    layer._name = layer.name + str(\"_2\")\n","\n","\n","moat3.load_weights('moat_pet_500_disjoint1_augment.h5')\n","moat4.load_weights('moat_pet_500_disjoint2_augment.h5')\n","\n","moat3.trainable=False\n","moat4.trainable=False\n","\n","en_input = Input(shape=(500,500,3))\n","x = moat3(en_input)\n","y = moat4(en_input)\n","\n","b1 = tf.keras.layers.Flatten(name='flatten_layer1')(x[\"stage5\"])\n","b2 = tf.keras.layers.Flatten(name='flatten_layer2')(y[\"stage5\"])\n","\n","z= tf.concat([b1, b2],axis=1)\n","z= tf.keras.layers.BatchNormalization()(z)\n","\n","en_out = Dense(units=37, activation='softmax', kernel_initializer=\"he_normal\")(z)\n","\n","def create_model3():\n","  return tf.keras.models.Model(inputs=en_input, outputs=en_out) \n","\n","#moat2 = moat.get_model(\n","#    name='tiny_moat0_pretrain_256_no_pe_1k',input_shape=[256,256,3])\n","#moat2 = moat._load_moat_pretrained_checkpoint(moat1, path=\"./model-ckpt-0\")\n","\n","with tf.device('/device:GPU:0'):\n","  en_model = create_model3()\n","  en_model.compile(optimizer=opt2,\n","              loss='sparse_categorical_crossentropy', metrics = tf.keras.metrics.SparseCategoricalAccuracy())\n","  checkpointer = ModelCheckpoint(filepath='ensemble_augment_1.hdf5', verbose=1, save_best_only=True)\n","  csv_logger = CSVLogger('ensemble_augment_1.log')\n","  history = en_model.fit_generator(train_generator, \n","                    steps_per_epoch = nb_train_samples // batch_size,      \n","                    validation_data=validation_generator,\n","                    validation_steps=nb_validation_samples // batch_size,  \n","                    epochs=30,                                             \n","                    verbose=1,\n","                    callbacks=[csv_logger, checkpointer])\n"],"id":"gwC1ZV0_K3ss"},{"cell_type":"markdown","metadata":{"id":"VxNte-20Tdmw"},"source":["### Ensemble finetuning"],"id":"VxNte-20Tdmw"},{"cell_type":"code","source":["first_decay_steps = 1000\n","initial_learning_rate = 5e-6\n","lr_decayed_fn = (\n","  tf.keras.experimental.CosineDecayRestarts(    \n","      initial_learning_rate,\n","      first_decay_steps))\n","\n","opt3 = AdaBeliefOptimizer(learning_rate=lr_decayed_fn, beta_1= 0.9, beta_2=0.999, weight_decay= 0.05,  epsilon=1e-14, clipnorm=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EowNrC8veHwa","executionInfo":{"status":"ok","timestamp":1671086836840,"user_tz":-540,"elapsed":6,"user":{"displayName":"신동욱","userId":"15777921251637057342"}},"outputId":"83693f2e-10e2-4485-9195-03e907600822"},"id":"EowNrC8veHwa","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n","\u001b[31mModifications to default arguments:\n","\u001b[31m                           eps  weight_decouple    rectify\n","-----------------------  -----  -----------------  -------------\n","adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",">=0.1.0 (Current 0.2.1)  1e-14  supported          default: True\n","\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n","----------------------------------------------------------  ----------------------------------------------\n","Recommended epsilon = 1e-7                                  Recommended epsilon = 1e-14\n","\u001b[34mFor a complete table of recommended hyperparameters, see\n","\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n","\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n","\u001b[0m\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QqEOkaBRGvM5","outputId":"ba42e9f3-9fc1-4543-b6f2-b05c6c961dde"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-9-c4c97a527752>:37: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  history = en_model2.fit_generator(train3_generator,\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n"," 84/644 [==>...........................] - ETA: 2:00:35 - loss: 0.1622 - sparse_categorical_accuracy: 0.9539"]}],"source":["moat3 = moat.get_model(name='tiny_moat1_pretrain_256_no_pe_1k',input_shape=[500,500,3])\n","moat4 = moat.get_model(name='tiny_moat1_pretrain_256_no_pe_1k',input_shape=[500,500,3])\n","moat3._name=\"moat3\"\n","moat4._name=\"moat4\"\n","\n","for layer in moat4.layers:\n","    layer._name = layer.name + str(\"_2\")\n","\n","en_input = Input(shape=(500,500,3))\n","x = moat3(en_input)\n","y = moat4(en_input)\n","\n","b1 = tf.keras.layers.Flatten(name='flatten_layer1')(x[\"stage5\"])\n","b2 = tf.keras.layers.Flatten(name='flatten_layer2')(y[\"stage5\"])\n","\n","z= tf.concat([b1, b2],axis=1)\n","z= tf.keras.layers.BatchNormalization()(z)\n","\n","en_out = Dense(units=37, activation='softmax', kernel_initializer=\"he_normal\")(z)\n","\n","def create_model3():\n","  return tf.keras.models.Model(inputs=en_input, outputs=en_out) \n","\n","en_model2 = create_model3()\n","\n","moat3.trainable=False\n","moat4.trainable=False\n","\n","en_model2.load_weights('ensemble_augment_1.hdf5')\n","\n","moat3.trainable=True\n","moat4.trainable=True\n","\n","with tf.device('/device:GPU:0'):\n","  en_model2.compile(optimizer=opt3,\n","              loss='sparse_categorical_crossentropy', metrics = tf.keras.metrics.SparseCategoricalAccuracy())\n","  history = en_model2.fit_generator(train3_generator, \n","                    steps_per_epoch = nb_train_samples // batch_size,      \n","                    validation_data=validation_generator,\n","                    validation_steps=nb_validation_samples // batch_size,  \n","                    epochs=30,                                             \n","                    verbose=1,\n","                    callbacks=[keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy', patience=10, restore_best_weights=True)])\n","  \n","moat3.trainable=False\n","moat4.trainable=False\n","\n","en_model2.save_weights('ensemble_augment_1_finetune.h5')"],"id":"QqEOkaBRGvM5"},{"cell_type":"markdown","metadata":{"id":"J5wXS9ZUd_CU"},"source":["## Model assessment"],"id":"J5wXS9ZUd_CU"},{"cell_type":"code","execution_count":null,"metadata":{"id":"PInitA9cJxND"},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import confusion_matrix,classification_report\n","\n","batch_size = 16\n","num_of_test_samples = nb_test_samples\n","\n","with tf.device('/device:GPU:0'):\n","  predictions = en_model2.predict_generator(test_generator)\n","\n","y_pred = np.argmax(predictions, axis=1)\n","true_classes = test_generator.classes\n","class_labels = list(test_generator.class_indices.keys())\n","\n","print(class_labels)\n","print(confusion_matrix(test_generator.classes, y_pred))\n","report = classification_report(true_classes, y_pred, target_names=class_labels, digits=5)\n","print(report)"],"id":"PInitA9cJxND"}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":5}