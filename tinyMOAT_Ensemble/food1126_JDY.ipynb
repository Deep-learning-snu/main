{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4a9ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copy\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import cv2\n",
    "import glob\n",
    "from PIL import Image, ImageEnhance\n",
    "import PIL.ImageOps\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# 0 = all messages are logged (default behavior)\n",
    "# 1 = INFO messages are not printed\n",
    "# 2 = INFO and WARNING messages are not printed\n",
    "# 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Theano(th)와 Tensorflow(tf) 모두와 호환이 되는 Keras 모듈을 작성\n",
    "import keras.backend as K\n",
    "from keras import regularizers\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Conv2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator # 데이터 전처리\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "#from keras.optimizers import SGD\n",
    "\n",
    "from keras_preprocessing.image import array_to_img, img_to_array, load_img\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from deeplab2.model.pixel_encoder import moat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2954d555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(filepath, src,dest):\n",
    "    classes_images = defaultdict(list)\n",
    "    with open(filepath, 'r') as txt:\n",
    "        paths = [read.strip() for read in txt.readlines()]\n",
    "        for p in paths:\n",
    "            food = p.split('/')\n",
    "            classes_images[food[0]].append(food[1] + '.jpg')\n",
    "    food_list=list(classes_images.keys())[0:30]\n",
    "    \n",
    "    for food in food_list:\n",
    "        if not os.path.exists(os.path.join(dest,food)):\n",
    "            os.makedirs(os.path.join(dest,food))\n",
    "        for i in classes_images[food]:\n",
    "            copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n",
    "    print(\"Copying Done!\",food_list)\n",
    "\n",
    "# 본인 환경에 맞게 food101 들어있는 디렉토리 설정하기\n",
    "prepare_data('/Volumes/T7/food-101/meta/train.txt', '/Volumes/T7/food-101/images', '/Volumes/T7/food-101/train')\n",
    "prepare_data('/Volumes/T7/food-101/meta/test.txt', '/Volumes/T7/food-101/images', '/Volumes/T7/food-101/test')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "177ba3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# releases the global state: avoid clutter from old models and layers\n",
    "K.clear_session()\n",
    "\n",
    "# 초기 변수 설정\n",
    "n_classes = 5\n",
    "\n",
    "### 이미지 크기 설정\n",
    "img_width, img_height = 256,256\n",
    "\n",
    "\n",
    "train_data_dir = '/Volumes/T7/food-101/train'\n",
    "validation_data_dir = '/Volumes/T7/food-101/test'\n",
    "nb_train_samples = 750*n_classes     # 3000 * 101\n",
    "nb_validation_samples = 250*n_classes  # 1000 * 101\n",
    "batch_size = 20                # 한 번 실행될 때 생성할 이미지 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b46bdb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator 객체 생성 (이미지 파일들을 Numpy Array 형태로 가져온 후 증강 기법 적용 준비)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./ 255,       # multiply the data by the value\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,        # Shear angle in counter-clockwise direction as radians\n",
    "    zoom_range=0.2,         # Range for random zoom. If a float\n",
    "    horizontal_flip=True,   # Randomly flip inputs horizontally\n",
    "    fill_mode='nearest')   \n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./ 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a93a9996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3750 images belonging to 5 classes.\n",
      "Found 1250 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# flow_from_directory : Numpy Array Iterator 객체 생성\n",
    "# 인자로 설정해주는 directory의 바로 하위 디렉토리 이름을 레이블이라고 간주, 그 디렉토리 아래의 파일들을 해당 레이블의 이미지들이라고 알아서 추측\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse')\n",
    "    #'categorical' : 멀티-레이블 클래스, 원-핫 인코딩된 형태\n",
    "    #'sparse' : 멀티-레이블 클래스, 레이블 인코딩된 형태\n",
    "    #'binary' : 이진 분류 클래스, 0 또는 1인 형태\n",
    "    \n",
    "    \n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56bd878",
   "metadata": {},
   "source": [
    "# 모델1 (바틀넥)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09ac874c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    }
   ],
   "source": [
    "moat1=moat.get_model(\n",
    "    name='tiny_moat0_pretrain_256_no_pe_1k',input_shape=[256,256,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5432353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "moat1 = moat._load_moat_pretrained_checkpoint(moat1, path=\"./model-ckpt-0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bced788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting adabelief_tf\n",
      "  Using cached adabelief_tf-0.2.1-py3-none-any.whl (6.4 kB)\n",
      "Installing collected packages: adabelief_tf\n",
      "Successfully installed adabelief_tf-0.2.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --no-deps --force-reinstall adabelief_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1df9779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stage1': (None, 128, 128, 32),\n",
       " 'res1': (None, 128, 128, 32),\n",
       " 'stage2': (None, 64, 64, 32),\n",
       " 'res2': (None, 64, 64, 32),\n",
       " 'stage3': (None, 32, 32, 64),\n",
       " 'res3': (None, 32, 32, 64),\n",
       " 'stage4': (None, 16, 16, 128),\n",
       " 'res4': (None, 16, 16, 128),\n",
       " 'stage5': (None, 8, 8, 256),\n",
       " 'res5': (None, 8, 8, 256)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import (Input, Dense, concatenate, Conv2D, MaxPooling2D, Flatten)\n",
    "from tensorflow import keras\n",
    "\n",
    "moat1.input_shape\n",
    "moat1.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57855eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y11 = moat1.output[\"stage1\"]\n",
    "y12 = moat1.output[\"res1\"]\n",
    "y21 = moat1.output[\"stage2\"]\n",
    "y22 = moat1.output[\"res2\"]\n",
    "y31 = moat1.output[\"stage3\"]\n",
    "y32 = moat1.output[\"res3\"]\n",
    "y41 = moat1.output[\"stage4\"]\n",
    "y42 = moat1.output[\"res4\"]\n",
    "y51 = moat1.output[\"stage5\"]\n",
    "y52 = moat1.output[\"res5\"]\n",
    "\n",
    "z1 = y11+y12\n",
    "z2 = y21+y22\n",
    "z3 = y31+y32\n",
    "z4 = y41+y42\n",
    "z5 = y51+y52\n",
    "\n",
    "a1=Conv2D(8,(1,1),activation='relu')(z1)\n",
    "a2=Conv2D(8,(3,3),activation='relu')(a1)\n",
    "a3=MaxPooling2D(2,2)(a2) \n",
    "a4=Conv2D(8,(3,3),activation='relu')(a3)\n",
    "a5=MaxPooling2D(2,2)(a4) \n",
    "a6=Conv2D(8,(3,3),activation='relu')(a5)\n",
    "a7=MaxPooling2D(2,2)(a6) \n",
    "a8=Conv2D(8,(3,3),activation='relu')(a7)\n",
    "a9=MaxPooling2D(2,2)(a8)\n",
    "a10=Conv2D(8,(3,3),activation='relu')(a9)\n",
    "a11=MaxPooling2D(2,2)(a10)\n",
    "a12=Conv2D(32,(1,1),activation='relu')(a11)\n",
    "aa1=Flatten(name='flatten_layer1')(a12)\n",
    "\n",
    "b1=Conv2D(8,(1,1),activation='relu')(z2)\n",
    "b2=Conv2D(8,(3,3),activation='relu')(b1)\n",
    "b3=MaxPooling2D(2,2)(b2) \n",
    "b4=Conv2D(8,(3,3),activation='relu')(b3)\n",
    "b5=MaxPooling2D(2,2)(b4) \n",
    "b6=Conv2D(8,(3,3),activation='relu')(b5)\n",
    "b7=MaxPooling2D(2,2)(b6) \n",
    "b8=Conv2D(8,(3,3),activation='relu')(b7)\n",
    "b9=MaxPooling2D(2,2)(b8)\n",
    "b10=Conv2D(32,(1,1),activation='relu')(b9)\n",
    "bb1=Flatten(name='flatten_layer2')(b10)\n",
    "\n",
    "c1=Conv2D(16,(1,1),activation='relu')(z3)\n",
    "c2=Conv2D(16,(3,3),activation='relu')(c1)\n",
    "c3=MaxPooling2D(2,2)(c2) \n",
    "c4=Conv2D(16,(3,3),activation='relu')(c3)\n",
    "c5=MaxPooling2D(2,2)(c4) \n",
    "c6=Conv2D(16,(3,3),activation='relu')(c5)\n",
    "c7=MaxPooling2D(2,2)(c6) \n",
    "c8=Conv2D(64,(1,1),activation='relu')(c7)\n",
    "cc1=Flatten(name='flatten_layer3')(c8)\n",
    "\n",
    "d1=Conv2D(32,(1,1),activation='relu')(z4)\n",
    "d2=Conv2D(32,(3,3),activation='relu')(d1)\n",
    "d3=MaxPooling2D(2,2)(d2) \n",
    "d4=Conv2D(32,(3,3),activation='relu')(d3)\n",
    "d5=MaxPooling2D(2,2)(d4) \n",
    "d6=Conv2D(128,(1,1),activation='relu')(d5)\n",
    "dd1=Flatten(name='flatten_layer4')(d6)\n",
    "\n",
    "e1=Conv2D(64,(1,1),activation='relu')(z5)\n",
    "e2=Conv2D(64,(3,3),activation='relu')(e1)\n",
    "e3=MaxPooling2D(2,2)(e2) \n",
    "e4=Conv2D(64,(2,2),activation='relu')(e3)\n",
    "e5=Conv2D(256,(1,1),activation='relu')(e4)\n",
    "ee1=Flatten(name='flatten_layer5')(e5)\n",
    "\n",
    "fc1=tf.concat([aa1,bb1,cc1,dd1,ee1],axis=1)\n",
    "out1=Dense(units=101, activation='softmax')(fc1)\n",
    "\n",
    "model1 = tf.keras.models.Model(moat1.input, out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e91e6479",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'adabelief_tf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model1\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel1check.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01madabelief_tf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AdaBeliefOptimizer\n\u001b[1;32m      4\u001b[0m opt \u001b[38;5;241m=\u001b[39m AdaBeliefOptimizer(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, beta_1\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m, beta_2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.999\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-4\u001b[39m,  epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-13\u001b[39m, rectify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m model1\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mopt,\n\u001b[1;32m      6\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mSparseCategoricalAccuracy())\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'adabelief_tf'"
     ]
    }
   ],
   "source": [
    "model1.load_weights('model1check.hdf5')\n",
    "\n",
    "from adabelief_tf import AdaBeliefOptimizer\n",
    "opt = AdaBeliefOptimizer(learning_rate=1e-3, beta_1= 0.9, beta_2=0.999, weight_decay= 1e-4,  epsilon=5e-13, rectify=True)\n",
    "model1.compile(optimizer=opt,\n",
    "              loss='sparse_categorical_crossentropy', metrics = tf.keras.metrics.SparseCategoricalAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2406034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d7d9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481511dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1db276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cddf6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92b3861",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
