{"cells":[{"cell_type":"markdown","id":"3645956b","metadata":{"id":"3645956b"},"source":["### colab으로 할 때만 실행"]},{"cell_type":"code","execution_count":null,"id":"6468006e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20797,"status":"ok","timestamp":1671289396236,"user":{"displayName":"­정다연 / 학생 / 통계학과","userId":"06805092502741452281"},"user_tz":-540},"id":"6468006e","outputId":"4a954c1e-c5cb-4321-d774-26ab3207071b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"id":"e11601b1","metadata":{"id":"e11601b1"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"id":"c238dcb2","metadata":{"id":"c238dcb2"},"outputs":[],"source":["import os\n","os.chdir(\"/content/drive/MyDrive\")"]},{"cell_type":"markdown","id":"62959a2a","metadata":{"id":"62959a2a"},"source":["### 설치 필요할때만"]},{"cell_type":"code","execution_count":null,"id":"eb01b889","metadata":{"id":"eb01b889"},"outputs":[],"source":["!python --version\n","!pip install opencv-python\n","!pip install tensorflow_datasets\n","!pip install -U scikit-learn\n","!pip install adabelief-tf"]},{"cell_type":"markdown","id":"317910c2","metadata":{"id":"317910c2"},"source":["### 기본 설정"]},{"cell_type":"code","execution_count":null,"id":"90beabc7","metadata":{"id":"90beabc7"},"outputs":[],"source":["from shutil import copy\n","from collections import defaultdict\n","import scipy\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import warnings\n","\n","import random\n","import cv2\n","import glob\n","from PIL import Image, ImageEnhance\n","import PIL.ImageOps\n","\n","import torch\n","import torchvision\n","from torch import nn\n","\n","\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","\n","# 0 = all messages are logged (default behavior)\n","# 1 = INFO messages are not printed\n","# 2 = INFO and WARNING messages are not printed\n","# 3 = INFO, WARNING, and ERROR messages are not printed\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.python.ops.clip_ops import clip_by_global_norm\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras import layers\n","import tensorflow_datasets as tfds\n","\n","\n","# Theano(th)와 Tensorflow(tf) 모두와 호환이 되는 Keras 모듈을 작성\n","import keras.backend as K\n","from keras import regularizers\n","from keras.applications.mobilenet_v2 import MobileNetV2\n","from keras.models import Model\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization, Dropout, Flatten, Dense, concatenate\n","from tensorflow.keras.utils import to_categorical\n","from keras.preprocessing.image import ImageDataGenerator # 데이터 전처리\n","from keras.callbacks import ModelCheckpoint, CSVLogger\n","#from keras.optimizers import SGD\n","\n","from keras_preprocessing.image import array_to_img, img_to_array, load_img\n","\n","from sklearn.model_selection import train_test_split\n","\n","\n","from deeplab2.model.pixel_encoder import moat\n","from adabelief_tf import AdaBeliefOptimizer"]},{"cell_type":"markdown","id":"67290bb3","metadata":{"id":"67290bb3"},"source":["### 데이터 다운로드 + split (한번만)\n","\n","https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz"]},{"cell_type":"code","execution_count":null,"id":"4ae34ca2","metadata":{"id":"4ae34ca2"},"outputs":[],"source":["#!tar -xvf \"/Users/dayeonjung/Desktop/deep/main/tinyMOAT_Ensemble/cifar10.tar\"\n","import splitfolders\n","splitfolders.ratio(\"cifar10/train/\", output = \"cifar10/output1/\", seed = 1337, ratio = (0.84, 0.16))\n","splitfolders.ratio(\"cifar10/train/\", output = \"cifar10/output2/\", seed = 1337, ratio = (0.42, 0.42, 0.16))"]},{"cell_type":"markdown","source":["### 압축풀기"],"metadata":{"id":"4XUpbySnnG-k"},"id":"4XUpbySnnG-k"},{"cell_type":"code","source":["!unzip -qq \"/content/drive/MyDrive/split.zip\""],"metadata":{"id":"nfRWwC0XnHUb"},"id":"nfRWwC0XnHUb","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"5c055066","metadata":{"id":"5c055066"},"source":["### 초기 설정"]},{"cell_type":"code","execution_count":null,"id":"361adc91","metadata":{"id":"361adc91"},"outputs":[],"source":["# 초기 변수 설정\n","n_classes = 10\n","\n","### 이미지 크기 설정\n","img_width, img_height = 256,256\n","\n","my_dir = os.getcwd()\n","train_data_dir = my_dir + '/split/train'\n","train1_data_dir = my_dir + '/split/train1'\n","train2_data_dir = my_dir + '/split/train2'\n","validation_data_dir = my_dir + '/split/val'\n","test_data_dir = my_dir + '/split/test'\n","\n","nb_train_samples =  42000\n","nb_train1_samples =  21000\n","nb_train2_samples =  21000\n","nb_validation_samples = 8000\n","nb_test_samples = 10000\n","batch_size = 100"]},{"cell_type":"code","execution_count":null,"id":"86ba7d9d","metadata":{"id":"86ba7d9d"},"outputs":[],"source":["# ImageDataGenerator 객체 생성 (이미지 파일들을 Numpy Array 형태로 가져온 후 증강 기법 적용 준비)\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.3,\n","    height_shift_range=0.3,\n","    shear_range=0.3,        # Shear angle in counter-clockwise direction as radians\n","    zoom_range=0.3,         # Range for random zoom. If a float\n","    horizontal_flip=True,   # Randomly flip inputs horizontally\n","    fill_mode='nearest') \n","\n","train1_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.3,\n","    height_shift_range=0.3,\n","    shear_range=0.3,        # Shear angle in counter-clockwise direction as radians\n","    zoom_range=0.3,         # Range for random zoom. If a float\n","    horizontal_flip=True,   # Randomly flip inputs horizontally\n","    fill_mode='nearest')   \n","\n","# ImageDataGenerator 객체 생성 (이미지 파일들을 Numpy Array 형태로 가져온 후 증강 기법 적용 준비)\n","train2_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.3,\n","    height_shift_range=0.3,\n","    shear_range=0.3,        # Shear angle in counter-clockwise direction as radians\n","    zoom_range=0.3,         # Range for random zoom. If a float\n","    horizontal_flip=True,   # Randomly flip inputs horizontally\n","    fill_mode='nearest') \n","\n","val_datagen = ImageDataGenerator(\n","    rescale=1./255,)\n","\n","test_datagen = ImageDataGenerator(\n","    rescale=1./255,)"]},{"cell_type":"code","execution_count":null,"id":"625e77bf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"625e77bf","executionInfo":{"status":"ok","timestamp":1671291808151,"user_tz":-540,"elapsed":3185,"user":{"displayName":"­정다연 / 학생 / 통계학과","userId":"06805092502741452281"}},"outputId":"d3598280-ea6e-4b5d-d7cd-a2a87a2647cd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 42000 images belonging to 10 classes.\n","Found 21000 images belonging to 10 classes.\n","Found 21000 images belonging to 10 classes.\n","Found 8000 images belonging to 10 classes.\n","Found 10000 images belonging to 10 classes.\n"]}],"source":["train_generator = train_datagen.flow_from_directory(\n","    train_data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='sparse')\n","\n","\n","train1_generator = train1_datagen.flow_from_directory(\n","    train1_data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='sparse')\n","\n","\n","train2_generator = train2_datagen.flow_from_directory(\n","    train2_data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='sparse')\n","    \n","\n","validation_generator = val_datagen.flow_from_directory(\n","    validation_data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    shuffle=False,\n","    class_mode='sparse')\n","\n","\n","test_generator = test_datagen.flow_from_directory(\n","    test_data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    shuffle=False,\n","    class_mode=None)"]},{"cell_type":"markdown","id":"d4a0fe36","metadata":{"id":"d4a0fe36"},"source":["### 모델 생성"]},{"cell_type":"code","execution_count":null,"id":"755177fc","metadata":{"id":"755177fc"},"outputs":[],"source":["moat1 = moat.get_model(name='tiny_moat1_pretrain_256_no_pe_1k',input_shape=[256,256,3])\n","moat1 = moat._load_moat_pretrained_checkpoint(moat1, path=\"./model-ckpt-0\")\n","\n","o1 = moat1.output[\"stage5\"]\n","r1 = tf.keras.layers.Flatten(name='flatten_layer1')(o1)\n","r1 = tf.keras.layers.BatchNormalization()(r1)\n","out1 = tf.keras.layers.Dense(\n","    units=10, activation='softmax', name='output_layer', kernel_initializer=\"he_normal\")(r1)  \n","\n","def create_model1():\n","    return tf.keras.models.Model(moat1.input, out1)"]},{"cell_type":"code","execution_count":null,"id":"310cee95","metadata":{"id":"310cee95"},"outputs":[],"source":["moat2 = moat.get_model(name='tiny_moat1_pretrain_256_no_pe_1k',input_shape=[256,256,3])\n","moat2 = moat._load_moat_pretrained_checkpoint(moat2, path=\"./model-ckpt-0\")\n","\n","o2 = moat2.output[\"stage5\"]\n","r2 = tf.keras.layers.Flatten(name='flatten_layer1')(o2)\n","r2 = tf.keras.layers.BatchNormalization()(r2)\n","out2 = tf.keras.layers.Dense(\n","    units=10, activation='softmax', name='output_layer', kernel_initializer=\"he_normal\")(r2)  \n","\n","def create_model2():\n","    return tf.keras.models.Model(moat2.input, out2)"]},{"cell_type":"markdown","id":"maxiojNL6r5M","metadata":{"id":"maxiojNL6r5M"},"source":["### Train 1"]},{"cell_type":"code","execution_count":null,"id":"f9dcdf28","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"f9dcdf28","executionInfo":{"status":"error","timestamp":1671291913459,"user_tz":-540,"elapsed":85233,"user":{"displayName":"­정다연 / 학생 / 통계학과","userId":"06805092502741452281"}},"outputId":"d96a4073-fb6f-4174-d8d9-4e41c55c5d55"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n","\u001b[31mModifications to default arguments:\n","\u001b[31m                           eps  weight_decouple    rectify\n","-----------------------  -----  -----------------  -------------\n","adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",">=0.1.0 (Current 0.2.1)  1e-14  supported          default: True\n","\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n","----------------------------------------------------------  ----------------------------------------------\n","Recommended epsilon = 1e-7                                  Recommended epsilon = 1e-14\n","\u001b[34mFor a complete table of recommended hyperparameters, see\n","\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n","\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n","\u001b[0m\n","Epoch 1/10\n"]},{"output_type":"error","ename":"ResourceExhaustedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-727dad4b6d81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mcsv_logger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCSVLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cifar10_final_disjoint_local_1_1.log'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m history = model1.fit(train1_generator,\n\u001b[0m\u001b[1;32m     15\u001b[0m                 \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb_train1_samples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/moat/block_01_00/Gelu/Erf' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 149, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 787, in inner\n      self.run()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 748, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n      yield self.process_one()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 225, in wrapper\n      runner = Runner(result, future, yielded)\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 714, in __init__\n      self.run()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 748, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-42-727dad4b6d81>\", line 14, in <module>\n      history = model1.fit(train1_generator,\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/content/drive/MyDrive/deeplab2/model/pixel_encoder/moat.py\", line 262, in call\n      for stage_id, stage_blocks in enumerate(self._blocks):\n    File \"/content/drive/MyDrive/deeplab2/model/pixel_encoder/moat.py\", line 263, in call\n      for block in stage_blocks:\n    File \"/content/drive/MyDrive/deeplab2/model/pixel_encoder/moat.py\", line 264, in call\n      output = block(output, training=training)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/content/drive/MyDrive/deeplab2/model/layers/moat_blocks.py\", line 290, in call\n      output = self._activation_fn(output)\nNode: 'model/moat/block_01_00/Gelu/Erf'\nfailed to allocate memory\n\t [[{{node model/moat/block_01_00/Gelu/Erf}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_80912]"]}],"source":["warnings.filterwarnings('ignore')\n","model1 = create_model1()\n","#model1.load_weights('cifar10_final_disjoint_local_1_1.hdf5')\n","\n","\n","opt = AdaBeliefOptimizer(learning_rate=1e-3, beta_1= 0.9, beta_2=0.999, weight_decay= 0.05,  epsilon=1e-14)\n","\n","model1.compile(optimizer=opt,\n","          loss='sparse_categorical_crossentropy', metrics = tf.keras.metrics.SparseCategoricalAccuracy())\n","\n","checkpointer = ModelCheckpoint(filepath='cifar10_final_disjoint_local_1_1.hdf5', verbose=1, monitor =\"val_sparse_categorical_accuracy\",save_best_only=True)\n","csv_logger = CSVLogger('cifar10_final_disjoint_local_1_1.log')\n","\n","history = model1.fit(train1_generator,\n","                steps_per_epoch = nb_train1_samples // batch_size,      \n","                validation_data=validation_generator,\n","                validation_steps=nb_validation_samples // batch_size,  \n","                epochs=10,                                             \n","                verbose=1,\n","                callbacks=[csv_logger, checkpointer])"]},{"cell_type":"code","execution_count":null,"id":"e020cef0","metadata":{"id":"e020cef0"},"outputs":[],"source":["model1 = create_model1()\n","model1.load_weights('cifar10_final_disjoint_local_1_1.hdf5')\n","\n","\n","opt = AdaBeliefOptimizer(learning_rate=1e-5, beta_1= 0.9, beta_2=0.999, weight_decay= 0.05,  epsilon=1e-14)\n","\n","model1.compile(optimizer=opt,\n","          loss='sparse_categorical_crossentropy', metrics = tf.keras.metrics.SparseCategoricalAccuracy())\n","\n","checkpointer = ModelCheckpoint(filepath='cifar10_final_disjoint_local_1_2.hdf5', verbose=1, monitor =\"val_sparse_categorical_accuracy\",save_best_only=True)\n","csv_logger = CSVLogger('cifar10_final_disjoint_local_1_2.log')\n","\n","history = model1.fit(train1_generator,\n","                steps_per_epoch = nb_train1_samples // batch_size,      \n","                validation_data=validation_generator,\n","                validation_steps=nb_validation_samples // batch_size,  \n","                epochs=300,                                             \n","                verbose=1,\n","                callbacks=[csv_logger, checkpointer])"]},{"cell_type":"code","execution_count":null,"id":"0e1deff6","metadata":{"id":"0e1deff6"},"outputs":[],"source":["model1.save_weights('cifar10_final_disjoint_zoomx_1_2_final.hdf5')"]},{"cell_type":"markdown","id":"00666b7e","metadata":{"id":"00666b7e"},"source":["### Train 2"]},{"cell_type":"code","execution_count":null,"id":"8fa20561","metadata":{"id":"8fa20561"},"outputs":[],"source":["batch_size = 200\n","train2_generator = train2_datagen.flow(x=tr2_images, y=tr2_labels, batch_size = batch_size, shuffle=True)\n","validation_generator = val_datagen.flow(x=val_images, y=val_labels, batch_size = batch_size, shuffle=False)\n","warnings.filterwarnings('ignore')\n","\n","model2 = create_model2()\n","#model2.load_weights('cifar10_final_disjoint_zoomx_2_1.hdf5')\n","\n","\n","opt = AdaBeliefOptimizer(learning_rate=1e-3, beta_1= 0.9, beta_2=0.999, weight_decay= 0.05,  epsilon=1e-14)\n","\n","model2.compile(optimizer=opt,\n","          loss='sparse_categorical_crossentropy', metrics = tf.keras.metrics.SparseCategoricalAccuracy())\n","\n","checkpointer = ModelCheckpoint(filepath='cifar10_final_disjoint_zoomx_2_1.hdf5', verbose=1, monitor =\"val_sparse_categorical_accuracy\",save_best_only=True)\n","csv_logger = CSVLogger('cifar10_final_disjoint_zoomx_2_1.log')\n","\n","history = model2.fit(train2_generator,\n","                steps_per_epoch = nb_train2_samples // batch_size,      \n","                validation_data=validation_generator,\n","                validation_steps=nb_validation_samples // batch_size,  \n","                epochs=20,                                             \n","                verbose=1,\n","                callbacks=[csv_logger, checkpointer])"]},{"cell_type":"code","execution_count":null,"id":"ca2d7f88","metadata":{"id":"ca2d7f88"},"outputs":[],"source":["batch_size = 200\n","train2_generator = train2_datagen.flow(x=tr2_images, y=tr2_labels, batch_size = batch_size, shuffle=True)\n","validation_generator = val_datagen.flow(x=val_images, y=val_labels, batch_size = batch_size, shuffle=False)\n","warnings.filterwarnings('ignore')\n","\n","model2 = create_model2()\n","model2.load_weights('cifar10_final_disjoint_zoomx_2_1.hdf5')\n","\n","\n","opt = AdaBeliefOptimizer(learning_rate=1e-5, beta_1= 0.9, beta_2=0.999, weight_decay= 0.05,  epsilon=1e-14)\n","\n","model2.compile(optimizer=opt,\n","          loss='sparse_categorical_crossentropy', metrics = tf.keras.metrics.SparseCategoricalAccuracy())\n","\n","checkpointer = ModelCheckpoint(filepath='cifar10_final_disjoint_zoomx_2_2.hdf5', verbose=1, monitor =\"val_sparse_categorical_accuracy\",save_best_only=True)\n","csv_logger = CSVLogger('cifar10_final_disjoint_zoomx_2_2.log')\n","\n","history = model2.fit(train2_generator,\n","                steps_per_epoch = nb_train2_samples // batch_size,      \n","                validation_data=validation_generator,\n","                validation_steps=nb_validation_samples // batch_size,  \n","                epochs=300,                                             \n","                verbose=1,\n","                callbacks=[csv_logger, checkpointer])"]},{"cell_type":"code","execution_count":null,"id":"4968aedb","metadata":{"id":"4968aedb"},"outputs":[],"source":["model2.save_weights('cifar10_final_disjoint_zoomx_2_2_final.hdf5')"]},{"cell_type":"code","execution_count":null,"id":"784cac5d","metadata":{"id":"784cac5d"},"outputs":[],"source":["moat2.save_weights('moat_cifar10_final_disjoint_zoomx_2_2_final.hdf5')"]},{"cell_type":"code","source":[],"metadata":{"id":"ONpMWA_Q3FSd"},"id":"ONpMWA_Q3FSd","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vesCordv3FAo"},"id":"vesCordv3FAo","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Tl8p5TRt3E8a"},"id":"Tl8p5TRt3E8a","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"yU8V1MaG3E3L"},"id":"yU8V1MaG3E3L","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WFESr_r-3E0p"},"id":"WFESr_r-3E0p","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":5}